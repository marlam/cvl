\input texinfo   @c -*-texinfo-*-
@afourpaper
@setfilename cvtool.info
@set UPDATED January 18, 2006
@set UPDATED-MONTH January 2006
@set EDITION 0.0.1
@set VERSION 0.0.1
@settitle cvtool @value{VERSION}

@c Define new index for commands
@defcodeindex cm

@finalout
@copying
This manual was last updated @value{UPDATED} for version
@value{VERSION} of cvtool.

Copyright @copyright{} 2005, 2006 Martin Lambers

@quotation
This program, including this manual, is free software; you can redistribute it
and/or modify it under the terms of the GNU General Public License as published
by the Free Software Foundation; either version 2 of the License, or (at your
option) any later version.

This program, including this manual, is distributed in the hope that it will be
useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
Public License for more details.

You should have received a copy of the GNU General Public License along with
this program and manual; if not, write to the Free Software Foundation, Inc.,
51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
@end quotation
@end copying

@dircategory Individual utilities
@direntry
* cvtool: (cvtool).	A computer vision tool.
@end direntry

@titlepage
@title cvtool
@subtitle A computer vision tool
@subtitle version @value{VERSION}, @value{UPDATED}
@author Martin Lambers (@email{marlam@@marlam.de})
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@contents

@ifnottex
@node Top
@top cvtool
@insertcopying
@end ifnottex

@menu
* Overview::
* Commands::
* Examples::
* Enhancing cvtool::
* Command index::
@end menu


@node Overview
@chapter Overview

@menu
* Concept::
* Supported file types::
* Output::
* Global options::
* Common parameters::
* Environment::
* Exit codes::
@end menu

@node Concept
@section Concept

Cvtool is a filter that manipulates one or more images: it reads images from
standard input and writes the manipulated images to standard output. It can
read and write streams of NetPBM images (ppm, pgm, pbm) and video streams in
the YUV4MPEG2 format used by the MJPEG Tools.

Cvtool integrates all its functionality into a single binary, and makes
it available through commands such as @code{rotate}, @code{smooth}, and 
others.

The following command scales a NetPBM image by a factor of 3:
@example
$ cvtool scale --factor 3.0 < input.ppm > output.ppm
@end example

This is how one would select a rectangle from a YUV4MPEG2 video stream:
@example
$ cvtool cut --left 10 --top 10 --width 100 --height 100 \
  < input.y4m > output.y4m
@end example

@code{cvtool help} prints a list of available commands, and 
@code{cvtool help cmd} prints help for the command @code{cmd}.


@node Supported file types
@section Supported file types

@subsection NetPBM formats: @samp{pnm}

All NetPBM image formats (pbm, pgm, ppm, pam) are supported, except for their
old "plain" variants. Multiple images in one file are supported. They may
differ in size and type.

Cvtool always uses 256 values per color channel. If the input uses a different
number, it will be converted, and a warning will be issued.

@subsection YUV4MPEG2 format: @samp{y4m}

Cvtool supports a subset of the YUV4MPEG2 format as used by MJPEG Tools.

The following features are not yet supported:
@itemize
@item Chroma subsampling other than 420jpeg and 444
@item X-tags for streams
@item X-tags for frames
@item Interlacing
@end itemize

Internally, cvtool works with chroma information for each pixel. This
corresponds to the 444 chroma subsampling type of the YUV4MPEG2 format.  The
420jpeg subsampling type stores chroma information only for groups of 4 pixels,
which may mean a loss of information.

Cvtool will keep the chroma type of the input files, which is 420jpeg in most cases, 
and it will use the 420jpeg type by default when creating new @samp{y4m} streams.
This is because many tools, including mpeg2enc and MPlayer, only accept 420jpeg subsampling.

To preserve the full chroma information across several stream manipulation
steps, the 444 subsampling must be requested explicitly, for example with the
convert command:
@example
$ cvtool convert --chroma 444 < input.y4m \
  | ... manipulate frames ... \
  | cvtool convert --chroma 420jpeg \
  | mpeg2enc -f4 -o video.mpg
@end example

@node Output
@section Output

Cvtool normally prints messages to @code{stderr}. It prepends messages with its
name, the level of information, and the name of the command.

The level of information is @code{DBG} for debugging messages, @code{INF} for
informational messages, @code{WRN} for warnings, @code{ERR} for error
messages, and @code{REQ} for requested information. Normally, cvtool prints only 
messages of level @code{INF} or higher, but this can be changed with 
@option{--quiet} and @option{--verbose}; see below.

Some commands, for example @command{info}, print special information messages
that the user explicitly requests. Such special messages have the level
@code{REQ}, and can usually be redirected using the @option{--output} option.
In this case, no additional information will be prepended to the messages.

The special filename @code{-} means standard output (@code{stdout}).
Redirecting messages to @code{stdout} is only allowed when no images are
written to @code{stdout}.


@node Global options
@section Global options

@table @code
@item -q|--quiet
Reduces the amount of output: only messages with level @code{WRN} 
and higher will be printed.

@item -v|--verbose
Increases the amount of output: all messages will be printed, even those
with level @code{DBG}. This will include progress information in many
cases, but much of the output is really only useful for debugging purposes.
@end table

@node Common parameters
@section Common parameters

@subsection Arrays and Matrices

Some commands need arrays of integer or floating point values as parameters.
Matrices are treated as two-dimensional arrays. Higher dimensions are also
possible.

All of these array types are treated the same: the first part of the argument
determines the number of dimensions of the array and its size in each
dimension. The second part lists all values, separated by commas.

If the command requests an array or matrix of fixed dimension and size (or of
dimension 1 and arbitrary size), then the first part can be omitted: only the
value list is necessary in this case.

Examples:
@itemize
@item An array with three integer values
@example
3:1,1,1
@end example
@item An array with five floating point values
@example
5:1.2,1.3,0.7,0.5,0.0
1.2,1.3,0.7,0.5,0.0
@end example
@item A 3x3 matrix array with integer values
@example
3x3:1,2,3,4,5,6,7,8,9
@end example
@item A three-dimensional array with floating point values
@example
2x2x2:1.11,1.12,1.21,1.22,2.11,2.12,2.21,2.22
@end example
@end itemize

@subsection Colors

Colors can be given in one of three forms:
@enumerate
@item X11 color names@*
X11 comes with a file rgb.txt that defines names for lots of colors.  Cvtool
accepts each of these names, case insensitively.  The full list can be found
here: @url{http://cvs.freedesktop.org/*checkout*/xorg/xc/programs/rgb/rgb.txt}.
@item Hex triplets@*
The RGB components of a color can be specified directly as a hex triplet:
@code{0xrrggbb}.  For example, @code{0x00ff00} is green, @code{0xffffff} is
white, and @code{0x000000} is black.
@item Decimal values@*
The RGB components of a color can be specified as decimal values, prepended
with r, g, or b.  For example, @code{g255} is green (the red and blue
components default to zero), @code{r255g255b255} is white, and @code{r0g0b0} is
black.
@end enumerate

@node Environment
@section Environment

@table @env
@item TMPDIR
Directory to create temporary files in.
@item COLUMNS
Cvtool tries to format its messages so that they do not use more than the given number of columns. 
If this variable is unset, a default of 80 will be used.
@end table

@node Exit codes
@section Exit codes

Cvtool returns @code{0} on success and @code{1} on error.


@node Commands
@chapter Commands

@menu
* Informational commands::
* Stream manipulation::
* Resizing frames::
* Transforming frames::
* Smoothing and Enhancing frames::
* Color manipulation::
* Detecting image features::
* Comparing frames::
* Stereoscopic image pairs::
* Miscellaneous::
@end menu

@node Informational commands
@section Informational commands

@cmindex help
@subsection help
@code{help [@var{command}]}

@noindent
Print general or command specific help.

@cmindex version
@subsection version
@code{version}

@noindent
Print version information.

@cmindex info
@subsection info
@code{info [-o|--output=@var{file}]}

@noindent
Print information about the first frame in a stream to stderr or to the given
file ('-' means stdout).@*
The following information will be printed: @code{STREAMTYPE} (@samp{y4m} or @samp{pnm}), 
@code{PIXELTYPE} (@samp{yuv} for @samp{y4m} streams, @samp{rgb} or @samp{gray} for @samp{pnm} streams),
@code{WIDTH}, @code{HEIGHT}, and, if @code{STREAMTYPE} is @samp{y4m}, @code{CHROMA}, 
@code{INTERLACING}, @code{FRAMERATE}, @code{ASPECTRATIO}.@*
In a @samp{y4m} stream, all frames are of the same type, and the information thus applies to 
the whole stream. This is not true for @samp{pnm} streams!
@example
$ cvtool info < file.pnm
cvtool: [INF] info: STREAMTYPE=pnm PIXELTYPE=rgb WIDTH=352 HEIGHT=240
$ eval `cvtool info -o - < file.pnm`
$ echo $WIDTH
352
@end example


@node Stream manipulation
@section Stream manipulation


@cmindex combine
@subsection combine
@code{combine [-m|--method=(lr|leftright)|(tb|topbottom)]
[-j|--justify=(left|top)|center|(right|bottom)] [-c|--color=@var{color}]
@var{file@dots{}}}

@noindent
Combine the given files by placing the frames side by side
(@samp{leftright}) or one below the other (@samp{topbottom}). The default
is @samp{leftright}. If the frames have different sizes, then the
smaller ones have to be aligned with the biggest one. The
default is to center them. The remaining space will be
filled with the given color; the default is black.
@example
$ cvtool combine left.pnm right.pnm > lr.pnm
$ cvtool combine -m tb \
  <(cvtool combine a.pnm b.pnm) \
  <(cvtool combine c.pnm d.pnm) \
  > 2x2.pnm
@end example

@cmindex convert
@subsection convert
@code{convert [-o|--output-type=pnm|y4m] [-g|--gray] [-C|--chroma=420jpeg|444]
[-F|--framerate=@var{f1:f2}] [-A|--aspect-ratio=@var{a1:a2}]}

@noindent
Convert input to @samp{pnm} or @samp{y4m} format. The default is to keep the input
format.@*
The @option{--gray} option converts each frame to graylevels. For the @samp{pnm}
output type, this is the only option that has any effect; the others are
silently ignored.@*
For @samp{y4m}, the chroma subsampling, frame rate, and aspect ratio can be
given. The default is to incur them from the input stream. If the input 
stream is not a @samp{y4m} stream, the defaults are @samp{0:0} ("unknown") 
for frame rate and aspect ratio, and @samp{420jpeg} for chroma subsampling.
@example
$ cvtool convert -C 444 < in.y4m > out.y4m 
$ cvtool convert -o pnm < video.y4m > video.pnm
@end example

@cmindex create
@subsection create
@code{create [-t|--type=gray|rgb|yuv] [-n|--n=@var{n}] -w|--width=@var{w}
-h|--height=@var{h} [-c|--color=@var{color}] [-C|--chroma=420jpeg|444]
[-F|--framerate=@var{f1:f2}] [-A|--aspect-ratio=@var{a1:a2}]}

@noindent
Create @var{n} (default 1) frames of pixel type @samp{gray}, 
@samp{rgb} or @samp{yuv} (default @samp{rgb}), with the given width and height, filled
with the given color (default black). The resulting stream
type will be @samp{pnm} for @samp{gray} and @samp{rgb} frames, and @samp{y4m}
for @samp{yuv} frames. The chroma subsampling, frame rate, and
aspect ratio information is only relevant for the @samp{yuv} type;
it will be silently ignored for the other types.
@example
$ cvtool create -t yuv -F 25:1 -w 720 -h 576 -n 250 > 10-seconds-PAL.y4m
$ cvtool create -t rgb -w 720 -h 576 -c green > green.pgm
@end example

@cmindex foreach
@subsection foreach
@code{foreach [-s|--shell=@var{shell}] [-n|--n=@var{n}] @var{cmd}}

@noindent
Execute the given command for every frame. The command is
expected to read @var{n} frames from standard input (default is @var{n}=1), 
and write an arbitrary number (including zero) of
frames to standard output. The original frame(s) that were
given to the command are replaced by the output of the
command. The frames that the command produces are converted
to the format of the original frames. The foreach command
replaces the following special strings in the command @var{cmd} 
before executing the command: @code{%N} (replaced with frame
number), @code{%W} (replaced with frame width), and @code{%H} (replaced
with frame height). If @var{n} is greater than 1, these values
refer to the first frame that is piped to the command.
The command @var{cmd} is executed by passing it to the system shell.
The default is @samp{/bin/sh -c} on most systems. This can be
overridden with the @option{--shell} option. It
expects a string with zero or one spaces: The first part of
the string is the shell, the second part (if any) is the
first option to the shell. The next option will then be the
command to execute.
@example
$ cvtool foreach 'cvtool info' < many-images.pnm

# Rotate a video. Use chroma 444 to allow odd width/height. Resize after 
# rotation to keep the original dimensions.
$ cvtool convert -C 444 < video.y4m \
  | cvtool foreach 'cvtool rotate -a %N | cvtool resize -w 352 -h 240' \
  | cvtool convert -C 420jpeg \
  > rotating-video.y4m
@end example

@cmindex merge
@subsection merge
@code{merge [-s|--shuffle] [-o|--output=@var{file}] @var{file@dots{}}}

@noindent
Merges files into one stream, in the given order. If
@code{--shuffle} is used, the order will be randomized. The file
names will be printed to stderr in the order they are
merged. If @code{--output} is used, the file names will be written
to the given file instead.
@example
$ ls
frame000.pnm frame001.pnm frame002.pnm
$ cvtool merge * | cvtool convert -o y4m > video.y4m
@end example

@cmindex reverse
@subsection reverse
@code{reverse}

@noindent
Reverses the order of the frames in the stream.
This requires a temporary file that is big enough to hold the complete input stream.
@example
$ cvtool reverse < video.y4m > oediv.y4m
@end example

@cmindex select
@subsection select
@code{select [-d|--drop] @var{range@dots{}}}

@noindent
Selects frames from a stream. By default, frames in the given ranges are kept and all others 
dropped. With @code{--drop}, frames in the given ranges are dropped and all others kept.@*
A range must be of the following form: @var{l}-@var{h} (from @var{l} to
@var{h}), -@var{h} (from beginning to @var{h}), @var{l}- (from @var{l} to end),
@var{l} (only @var{l}), or - (everything).  Each start and end point can be a
frame number (counting from 0) or a time in the format
[hours:]minutes:seconds[.fraction]. In short: if it contains a colon, it's a
time. Time ranges can only be used for YUV4MPEG2 streams with known frame rate.
IMPORTANT: If you use frame number ranges, the high frame number is inclusive:
the frame with this number will be dropped/kept. If you use time ranges, the
high time is exclusive and marks the first frame that will not be dropped/kept.
@example
# Drop the frames 0 to 124 from the stream (with a framerate of 25 fps,
# these are the first five seconds).
$ cvtool select --drop 0-124 < in.y4m > out.y4m

# Drop the first 5 seconds of the stream (with a framerate of 25 fps,
# these are the frames 0 to 124. The frame at 0:05, with the frame 
# number 125, will be the first that is kept!)
$ cvtool select --drop 0:00-0:05 < in.y4m > out.y4m

# Keep the second 5-minutes-block and drop all the rest. Both 
# commands are equivalent.
$ cvtool select 5:00-10:00 < in.y4m > out.y4m
$ cvtool select --drop -5:00 10:00- < in.y4m > out.y4m
@end example

@cmindex split
@subsection split
@code{split [-n|--n=@var{n}] [-t|--template=@var{template}] [-b|--backwards]
[-s|--start=@var{i}]}

@noindent
Split the input stream into multiple files, each containing
@var{n} frames (default is @var{n}=1). The filename will be generated
from the template: the template must contain exactly one
appearance of the character @code{%}. This character must be
followed by one of the digits @code{1} through @code{9}. The digit must be
followed by the uppercase character @code{N}. This special string
@code{%xN} will be replaced by the number of the first frame of the
stream contained in this file. The number will be
left-padded with zeros until its width is at least @code{x}
characters. The default template is @samp{frame-%6N}.
A start number i for the first frame can be given, and the
frames can be counted backwards. If the frames are counted
backwards, a start number is required, because negative
frame numbers are not accepted.
@example
$ cvtool split -t frame%3N.pnm < ../video.y4m
$ ls
frame000.pnm frame001.pnm frame002.pnm
$ cvtool split -s 99 -b -t img%2N.pnm < ../video.y4m
$ ls
img99.pnm img98.pnm img97.pnm
@end example

@node Resizing frames
@section Resizing frames

@cmindex resize
@subsection resize
@code{resize -w|--width=@var{w} -h|--height=@var{h} [-x|--x-offset=@var{x}]
[-y|--y-offset=@var{y}] [-c|--color=@var{color}]}

@noindent
Resize the frames to the given new width and height. Place
the original frame contents at the position (@var{x},@var{y}) relative
to the new frame (these offsets may be negative). If no or
an incomplete position is given, compute the missing part(s)
so that the old contents are centered on the new frame. Fill
holes that might result with the given color (default is
black).
@example
$ cvtool info < img.pnm
cvtool: [INF] info: STREAMTYPE=pnm PIXELTYPE=rgb WIDTH=352 HEIGHT=240
# Add a green border of 10 pixels
$ cvtool resize -w 372 -h 260 -c green < img.pnm > img2.pnm
@end example

@cmindex cut
@subsection cut
@code{cut -l|--left=@var{l} -t|--top=@var{t} -w|--width=@var{w}
-h|--height=@var{h}}

@noindent
Only let the given rectangle through; cut the rest of each frame.
@example
$ cvtool cut -l 0 -t 0 -w 10 -h 10 < in.pnm > out.pnm
@end example


@node Transforming frames
@section Transforming frames

@cmindex affine
@subsection affine
@code{affine -m|--matrix=@var{2x2-matrix} [-c|--color=@var{color}]
[-i|--interpolation=none|bilinear]}

@noindent
Apply the affine tranformation defined by the given matrix
(4 floating point values separated by commas) to the frames.
The frame dimensions will be adapted so that the resulting
image will fit. Possible holes will be filled with the given
color; the default is black. The default interpolation type
is bilinear.
@example
$ cvtool affine -m 2.0,0.1,0.75,1.0 < in.pnm > out.pnm
@end example

@cmindex flip
@subsection flip
@code{flip}

@noindent
Flip frames (left/right).
@example
$ cvtool flip < in.pnm > out.pnm
@end example

@cmindex flop
@subsection flop
@code{flop}

@noindent
Flop frames (top/bottom).
@example
$ cvtool flop < in.pnm > out.pnm
@end example

@cmindex rotate
@subsection rotate
@code{rotate -a|--angle=@var{angle} [-c|--color=@var{color}]
[-i|--interpolation=none|bilinear]}

@noindent
Rotate frames with the given angle (in degrees),
counterclockwise. The dimensions of the rotated frame will
be big enough to hold all informations from the source.
"Holes" will be filled with the given color; the default is
black. The default interpolation type is bilinear (simple
rotations (90, 180, or 270) do not need interpolation).
@example
$ cvtool rotate -a -45 < in.pnm > out.pnm
@end example

@cmindex scale
@subsection scale
@code{scale [-w|--width=@var{w}] [-h|--height=@var{h}]
[-i|--interpolation=none|bilinear]}@*
@code{scale -x|--factor-x=@var{factor-x} -y|--factor-y=@var{factor-y}
[-i|--interpolation=none|bilinear]}@*
@code{scale -f|--factor=@var{factor} [-i|--interpolation=none|bilinear]}

@noindent
Scale frames to new size. The default interpolation type is bilinear.@*
First form: Give new width and/or height. If one value is missing, it is
computed from the other so that the aspect ratio remains the same.@*
Second form: Give scale factors for width and height.@*
Third form: Give one scale factor for both width and height.
@example
$ cvtool info < in.pnm
cvtool: [INF] info: STREAMTYPE=pnm PIXELTYPE=rgb WIDTH=400 HEIGHT=200
# The following three commands do the same:
$ cvtool scale -w 100 -h 50    < in.pnm > out.pnm
$ cvtool scale -x 0.25 -y 0.25 < in.pnm > out.pnm
$ cvtool scale -f 0.25         < in.pnm > out.pnm
@end example

@cmindex shear
@subsection shear
@code{shear [-x|--shear-x=@var{angle-x}] [-y|--shear-y=@var{angle-y}] [-c|--color=@var{color}] 
[-i|--interpolation=none|bilinear]}

@noindent
Shear frames in horizontal and/or vertical direction, with the given angle(s)
from (-90,90). Negative angles shear clockwise. "Holes" will be filled with the
given color; the default is black. The default interpolation type is bilinear.
@example
$ cvtool shear -x 20 -y 10 < in.pnm > out.pnm
@end example


@node Smoothing and Enhancing frames
@section Smoothing and Enhancing frames

@cmindex smooth
@subsection smooth
@code{smooth average [-3|--3d] -k|--k=@var{k}}@*
@code{smooth average [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky} [-t|--k-t=@var{kt}]}@*
@code{smooth median [-3|--3d] -k|--k=@var{k}}@*
@code{smooth median [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky} [-t|--k-t=@var{kt}]}@*
@code{smooth gauss [-3|--3d] -k|--k=@var{k}}@*
@code{smooth gauss [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky} [-t|--k-t=@var{kt}]}@*
@code{smooth gauss [-3|--3d] [-k|--k=@var{k}] [-x|--k-x=@var{kx}]
[-y|--k-y=@var{ky}] [-t|--k-t=@var{kt}] [-s|--sigma=@var{s}]
[--sigma-x=@var{sx}] [--sigma-y=@var{sy}] [--sigma-t=@var{st}]}

@noindent
Smooth frames, in 2D or 3D (with the third dimension being the
time). The kernel size can be given for each dimension, or
once for all. It will be (2@var{kx}+1)x(2@var{ky}+1)[x(2@var{kt}+1)]. Different
values for each direction lead to asymmetric smoothing. The
gauss filter can be specified by the sigma value(s): the
mask size will be computed so that roughly 95% of the mass
lies within the resulting mask. It is also possible to
specify both @var{sigma} and @var{k}.
@example
$ cvtool smooth gauss --3d -k 3 < video.y4m > smoothed-video.y4m
@end example

@cmindex convolve
@subsection convolve
@code{convolve -K|--kernel=@var{K}}@*
@code{convolve -X|--vector-x=@var{X} -Y|--vector-y=@var{Y} [-T|--vector-t=@var{T}]}

@noindent
Convolve frames with the given convolution kernel. Both 2D
and 3D kernels are accepted (the third dimension is the
time). If the kernel is separable, the vectors that generate
it can be given instead, to reduce computation costs. All
kernel elements must be integers. The size of the kernel
must be an odd number in each dimension.
@example
# Both commands are equivalent to 2D smoothing with the 
# average filter with k=1:
$ cvtool convolve -K 3x3:1,1,1,1,1,1,1,1,1 < in.pnm > out.pnm
$ cvtool convolve -X 3:1,1,1 -Y 3:1,1,1    < in.pnm > out.pnm
@end example


@node Color manipulation
@section Color manipulation

@cmindex binarize
@subsection binarize
@code{binarize global -t|--threshold=@var{t}}@*
@code{binarize iterative}@*
@code{binarize otsu}@*
@code{binarize hysterese -l|--low=@var{l} -h|--high=@var{h}}@*
@code{binarize local -T|--type=mean|median|minmax -k|--k=@var{k} -C|--constant=@var{C}}

@noindent
Convert input to grayscale (if necessary), then binarize it
using the given method.@*
The global method turns every pixel to black whose value is
lower than the given threshold; all over pixels are turned
to white. The threshold must be from [0,256].@*
The iterative and otsu methods are global methods, too, but
they compute the threshold automatically.@*
The hysterese method is not adequate for general images; it
is mainly used by the Canny edge detector. It uses a low and
a high threshold; both must be in [0,255], and should be
chosen so that 2@var{l} <= @var{h} <= 4@var{l}.@*
The local method uses a local threshold (@var{T}-@var{C}) for a
neighborhood of size (2@var{k}+1)x(2@var{k}+1), where @var{T} is the mean of all
pixel values in the neighborhood, the median of the pixel
values, or the mean of the minimum and maximum of the pixel
values. @var{C} can be negative. The mean type is much faster than
median and minmax.
@example
$ cvtool binarize local -T median -k 5 -C 20 < gray.pgm > bw.pgm
@end example

@cmindex channel
@subsection channel
@code{channel -c|--channel=r|g|b}

@noindent
Pick the given channel from the input.
@example
$ cvtool channel -c r < colored.pnm > red.pnm
@end example

@cmindex color
@subsection color
@code{color [-h|--hue=@var{h}] [-s|--saturation=@var{s}]
[-l|--lightness=@var{l}] [-c|--contrast=@var{c}] 
[-g|--gamma=(@var{g}|@var{gr},@var{gg},@var{gb})]}

@noindent
Color adjustment.@*
Hue, saturation, lightness, and constrast are manipulated in
the HSL (Hue, Saturation, Lightness) color space. @var{h} is an
additive constant to the hue angle, in degrees. @var{s}, @var{l}, @var{c}
measure the relative change in saturation, lightness,
contrast: -1 means the result will be zero, 0 means the
result will be the same as the original, and +1 means that
the result will be two times as high as the original. Values
greater than +1 are possible. For example, s = -1 will
convert the input images to graylevels. See the 
@url{http://en.wikipedia.org/wiki/HLS_color_space,Wikipedia entry for HSL color space}
for more information.@*
Gamma correction (option @option{--gamma} is applied to the gray channel for
@samp{gray} frames, to the Y channel for @samp{yuv} frames, and to the R,G,B
channels for @samp{rgb} frames.  If three gamma values are given, the frames
are always converted to @samp{rgb}, then gamma corrected for each channel
separately, and then converted back to their original type. All gamma values
must be greater than zero. Values greater than 1.0 lighten the image, values
smaller than 1.0 darken them.
@example
$ cvtool color -h 120 < red.pnm > green.pnm
$ cvtool color -h 120 < green.pnm > blue.pnm
$ cvtool color -h 120 < blue.pnm > red.pnm
$ cvtool color -s -1 < colored.pnm > gray.pnm
$ cvtool color -l +1 < dark.pnm > light.pnm
$ cvtool color --gamma 1.4 < dark.pnm > light.pnm
@end example

@cmindex equalize
@subsection equalize
@code{equalize}

@noindent
Equalize Histogram. Color images are equalized in the Y part
of the YUV color space.
@example
$ cvtool equalize < in.pnm > out.pnm
@end example

@cmindex invert
@subsection invert
@code{invert}

@noindent
Invert input frames.
@example
$ cvtool invert < in.pnm > out.pnm
@end example


@node Detecting image features
@section Detecting image features

@cmindex edge
@subsection edge
@code{edge sobel}@*
@code{edge canny -s|--sigma=@var{sigma} -l|--low=@var{l} -h|--high=@var{h}}

@noindent
Detect edges.@*
Sobel will generate graylevel images: the brighter a point, the stronger the edge.@*
Canny will generate binary images. The @var{sigma} parameter is for Gauss smoothing.
@var{l} and @var{h} are used for Hysterese thresholding; both must be from [0,255].
@example
$ cvtool edge sobel < in.pgm > gray-edges.pgm
$ cvtool edge canny -s 1.2 -l 4 -h 8 < in.pgm > bw-edges.pgm
@end example

@cmindex opticalflow
@subsection opticalflow
@code{opticalflow hs [-b|--backwards] -l|--lambda=@var{l}
-n|--iterations=@var{n}}@*
@code{opticalflow lk [-b|--backwards] -k|--k=@var{k}}@*
@code{opticalflow clg [-b|--backwards] -l|--lambda=@var{l} -O|--omega=@var{O}
-n|--iterations=@var{n}}@*
@code{opticalflow bm-sad [-b|--backwards] -k|--k=@var{k}
-M|--max-distance=@var{m} -D|--distance-weight=@var{dw}
-L|--luminance-weight=@var{lw}}@*
@code{opticalflow bm-asw [-b|--backwards] -k|--k=@var{k}
-M|--max-distance=@var{m} -c|--gamma-c=@var{gc} -p|--gamma-p=@var{gp}}@*
@code{opticalflow cc -t|--tolerance=@var{t} [-w|--warning-level=@var{w}]
[-o|--output=@var{file}] -f|--verification-flow=@var{file}}

@noindent
Compute the optical flow between frames. For @var{n} input frames, this command will
produce @var{n}-1 fields of optical flow vectors, in plain text format: the first will contain
the optical flow between the input frames 0 and 1, the second that between 1 and 2, and so forth@*
If the @code{--backwards} option is used, then the optical flow is computed in the opposite direction:
the first flow field will contain the optical flow between frames 1 and 0, the second that between 2 and 1, 
and so forth.@*
The @emph{hs} (Horn/Schunck) method needs a regularisation parameter lambda (try
10.0), and the number of iterations (try 50).@*
The @emph{lk} (Lukas/Kanade) method needs the neighborhood size (2@var{k}+1)x(2@var{k}+1) as a
parameter.@*
The @emph{clg} (Combined Local/Global) method needs a regularization parameter lambda
(try 10.0), a relaxation parameter omega for the iterative SOR method (try
1.95; the value must be between 0 and 2), and the number of iterations (try
50).@*
The @emph{bm-sad} (block matching with sum of absoulte differences) method needs the
block size (2@var{k}+1)x(2@var{k}+1) as a parameter, and the maximum distance that matching
blocks will be searched in. The cost of a block are (dw \cdot distance + (1 - dw) \cdot
average_pixel_difference). The maximum norm distance is used here. Each pixel
difference is calculated with (lw * difference_in_luminance + (1 - lw) *
difference_in_chrominance. The block with the lowest cost is the match; it
determines the optical flow in a given point.  Warning: This method is VERY
SLOW!@*
The @emph{bm-asw} (block matching using adaptive support weights) method is a block
matching variant that uses special support weights for cost computation. Try 12
for @var{k}, 7 for @var{gc} and 36 for @var{gp}. This implementation uses a resolution
pyramid to speed the process up and reduce uncertainty in correspondence search.
Warning: This method is SLOW!@*
The @emph{cc} (consistency check) method does not compute optical flow from images.
Instead, it offers the verification step that improves existing optical flow fields:
the flow fields from @code{stdin} are compared against those from the given file. 
Each flow vector in the first set of fields must match its corresponding flow vector in the
second set of fields with the given tolerance. Vector pairs that differ by more than the 
given tolerance are marked as unreliable, and are replaced by interpolations of neighboring 
reliable vectors. If a warning level between 0 and 1 is given and the fraction of unreliable
vectors is greater than or equal to this level, then a warning is issued for the current flow field pair.
These warnings can be redirected to a separate file with the @code{--output} option.
@example
$ cvtool opticalflow bm-sad    -k 8 -M 5 -D 0.01 -L 0.5 \
  < video.y4m > flow-fw.txt
$ cvtool opticalflow bm-sad -b -k 8 -M 5 -D 0.01 -L 0.5 \
  < video.y4m > flow-bw.txt
$ cvtool opticalflow cc -t 2 -f flow-bw.txt \
  < flow-fw.txt > flow-fw-improved.txt
$ cvtool opticalflow cc -t 2 -f flow-fw.txt \
  < flow-bw.txt > flow-bw-improved.txt
@end example
@noindent 
See also:
@itemize @asis
@item For the @code{hs} method:@*
B. Horn and B. Schunck. Determining Optical Flow. @cite{Artificial Intelligence,}
17:185-203, 1981.
@item For the @code{lk} method:@*
B. D. Lucas T. and Kanade. An Iterative Image Registration Technique with
an Application to Stereo Vision. In @cite{Proceedings of the Seventh International
Joint Conference on Artificial Intelligence,} pages 674-679, Vancouver, BC,
Canada, April 1981.    
@item For the @code{clg} method:@*
A. Bruhn, J. Weickert, and C. Schn@"orr. Lucas/Kanade Meets Horn/Schunck:
Combining Local and Global Optic Flow Methods. @cite{International Journal of
Computer Vision,} 61(3):211-231, 2005.
@item For the @code{bm-sad} method:@*
TODO
@item For the @code{bm-asw} method:@*
K.-J. Yoon and I.-S. Kweon. Locally Adaptive Support-Weight Approach
for Visual Correspondence Search. In @cite{Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition (CVPR),} volume 2, pages 924-931, 
San Diego, CA, USA, June 2005. 
@end itemize

@node Comparing frames
@section Comparing frames

@cmindex diff
@subsection diff
@code{diff [-o|--output=@var{file}] @var{file-1} @var{file-2}}

@noindent
Shows the differences between the two sources. The sources must have the same
pixel type, width, and height. This command produces frames of the same
dimensions and of the same pixel type. Each pixel will be the absolute value of
the difference of the corresponding pixels in the two sources. The difference
is computed separated by color channels. Example: p1 = (r11, g12, b13), 
p2 = (r3, g11, b13) => (r8, g1, b0).@*
In addition to the difference frames, the command will compute the sum of the
absolute differences of all pixel values, divided by the number of pixels. The
value will be printed to stderr, unless the output is redirected with the @option{--output}
option. If the output is redirected to @code{stdout} (-), then only the difference values
and no frames will be written to @code{stdout}.
@samp{rgb} and @samp{yuv} frames produce three error values (one per channel),
printed on a single line.
@example 
$ cvtool create -w 10 -h 10 -c 255,0,0 > red.pnm
$ cvtool create -w 10 -h 10 -c 0,255,0 > green.pnm
$ cvtool diff red.pnm green.pnm > diff.pnm
cvtool: [REQ] diff: 255 255 0
@end example


@node Stereoscopic image pairs
@section Stereoscopic image pairs

@cmindex dibr
@subsection dibr
@code{dibr -d|--depth=@var{depthsource} -b|--b=@var{b} [-p|--position=@var{p}]
[-z|--zps=@var{z}] [-h|--hole-filling=none|average|near|far|linear]}

@noindent
Builds stereo images from a source view and corresponding
depth maps. @var{b} is the "eye" distance in pixels. The position
of the source view must be in [-1,+1], where -1 means left
view, +1 means right view, and 0 means intermediate view
(this is the default). @var{zps} is the zero parallax setting. It
must be in [0,1]; the default is 0. The hole filling method
can be none, average color (default), color of
nearer/farther neighbor pixel, or linear color gradient.
@example
$ cvtool dibr -d depth.pgm -b 20 < mono.pnm > stereo.pnm
@end example
@noindent 
See also:
@itemize @asis
@item C. Fehn, K. Hopf, and B. Quante. Key Technologies for an Advanced 3D-TV
System. In @cite{Proceedings of SPIE Three-Dimensional TV, Video and Display
III,} pages 66-80, Philadelphia, PA, USA, October 2004.	
@item L. Zhang and W. J. Tam. Stereoscopic Image Generation Based on Depth
Images for 3D TV. @cite{IEEE Transactions on Broadcasting,} 51(2):191-199, June 2005.	  
@item TODO
@end itemize

@cmindex stereoview
@subsection stereoview
@code{stereoview anaglyph [-c|--color[=on|off]] [-g|--glasses=red-cyan|red-green|red-blue]}@*
@code{stereoview 3d-display -f|--format=lr|tb|ci|ri [-w|--width=@var{w}] [-h|--height=@var{h}]}

@noindent
Prepares stereoscopic image pairs for a display device.@*
@code{anaglyph}: converts stereo frames (left and right view side by side) into
anaglyph images, viewable with appropriate color 3D glasses. The default is to
create graylevel anaglyphs for @samp{red-blue} glasses. It is advisable to lighten the images with
gamma correction before creating anaglyph images, because the glasses absorb some
lightness.@*
@code{3d-display}: convert stereo frames (left and right view side by side) into a
format that can be viewed directly on a 3D display by 
@url{http://www.dti3d.com/,DTI}: just play the resulting video with any media player in
fullscreen mode.  The width and height parameters should be set to the
resolution of the 3D display; the default is 1280x1024. The formats are: @samp{lr} =
left-right (S/S on DTI display), @samp{tb} = top-bottom (T/B on DTI display), @samp{ci} =
column-interleaved (Fr/S on DTI display), @samp{ri} = row-interleaved (F/S on DTI
display). If unsure, try @samp{tb}.
@example
$ cvtool stereoview anaglyph -c -g red-cyan < stereo.pnm > anaglyph.pnm
$ cvtool stereoview 3d-display -f tb < stereo.pnm > dti-stereo.pnm
@end example


@cmindex trackdepth
@subsection trackdepth
@anchor{trackdepth}
@code{trackdepth -n|--n=@var{n} -d|--depthmap-list=@var{d0},@var{d1},@dots{}
-f|--flow-forward=@var{flow-fw} -F|--flow-backward=@var{flow-bw}
@var{depthfile0} @var{depthfile1} @dots{}}

@noindent
Creates @var{n} depth maps by using depth tracking with the given
flow information on the given list of depth maps. The depth
map list contains the numbers of the frames for which a
depth map is available. It must be in ascending order. It is
not necessary to give a depth map for the first and last
frame (0 and @var{n}-1), but it may improve the results. Exactly
one depth map file must be given for each entry in the list.@*
This command uses temporary files that can become quite large.
@example
$ cvtool trackdepth -n 26 -d 0,25 -f flow-fw.txt -F flow-bw.txt \
  depth00.pgm depth25.pgm < video.y4m > depth00-25.pgm
@end example
@noindent 
See also:
@itemize @asis
@item TODO
@end itemize

@node Miscellaneous
@section Miscellaneous

@cmindex blend
@subsection blend
@code{blend -s|--source=@var{file} [-a|--alpha=@var{file}] [-S|--single]
[-x|--x=@var{x}] [-y|--y=@var{y}]}

@noindent
Blends the source into the image stream, using the alpha
map a. With no alpha map, the source is simply copied into
the images. @var{x} and @var{y} specify the position that the source
should be copied to. The default is (0,0). Positions outside of
the images are possible: parts of the source that do not fit
into the images will be ignored. When @option{--single} is used, only
the first frame of the source will be used; this frame will
be copied into all images of the stream.
@example
$ cvtool blend --single -s logo.pnm -a logo-alpha.pgm -x 700 -y 0 \
  < video.y4m > video-with-logo.y4m
@end example

@cmindex grid
@subsection grid
@code{grid}

@noindent
This command needs to be rewritten.

@cmindex vectors
@subsection vectors
@code{vectors visualize -t|--type=2i|2|3 [-x|--sample-x=@var{x}]
[-y|--sample-y=@var{y}] [-X|--dist-x=@var{dx}] [-Y|--dist-y=@var{dy}]
[-f|--factor=@var{f}]}

@noindent
Reads vector fields in plain text formats, as produced by other commands such
as opticalflow, and visualizes them as a needle diagram. The type of the
vectors must be known; it can be @samp{2i} for vectors with two integer components,
@samp{2} for vectors with two floating point components, and @samp{3} for vectors with
three floating point components.@*
Every @var{x}-th vector in horizontal direction and every @var{y}-th vector in vertical
direction will be represented by a needle. The needles will have a distance of
dx pixels in horizontal and dy pixels in vertical direction. The needle length
is the length of the vector after it was scaled with the factor @var{f}.@*
Example: @var{x=y=1}, @var{dx=dy=5} will result in a needle diagram that is 5 times
wider and higher than the input vector field. Every vector in it is visualized.
For @var{x=y=5}, the needle diagram is as big as the input vector field, but only one
of 25 vectors is visualized. The default is @var{x=y=dx=dy=10}, @var{f=1.0}.
@example
$ cvtool vectors visualize -t 2i < flow-fw.txt > flow-fw.pgm
@end example



@node Examples
@chapter Examples

@menu
* Creating a stereoscopic image from a single 2D image::
* Creating a stereoscopic video from a 2D video::
@end menu

@node Creating a stereoscopic image from a single 2D image
@section Creating a stereoscopic image from a single 2D image

@subsection Introduction 

A stereoscopic image is a pair of two images: one right view of a scene and one
left view. When a stereoscopic image is viewed in a way that lets the right eye
see the right view and the left eye the left view, a 3D effect is perceived: 
the human visible system can estimate the distance of an object in the scene from
the slightly different position that each object has in the two views.

Normally, stereoscopic images are created by taking photos from two cameras
that are arranged side by side, like two eyes.  To create a stereoscopic image
from a single 2D image, one has to reverse the distance estimation of the human
visible system: when the distance of an object in the scene is known, its
different positions in the left and right view can be estimated. This process is 
called Depth Image Based Rendering (DIBR).

DIBR uses depth maps are used. A depth map is a graylevel image with the
same dimensions as the original 2D image. For each pixel, it stores the distance
of the corresponding object in the 2D image. Graylevel 0 (black) means "far", and
graylevel 255 (white) means "near".

If you're lucky, you can record depth maps with a range sensor. All others have to
fake the depth maps. Fortunately, it turns out that the human visible system can 
easily be tricked, and that the depth maps do not need to be accurate at all.

@subsection Creating a depth map 

@ref{Figure nasac000} shows an image that was taken from a NASA mission video.
A simplistic depth map for this image was created with the Gimp; it is shown in
figure @ref{Figure nasad000}. It consists of three depth steps ("near", "very near", 
"middle") for parts of the shuttle, and a sphere in the "far" range that 
represents the earth. This sphere may not be visible in the depth map because of 
the dark shades of gray that were used for it. It is probably not necessary anyway.

@float Figure,Figure nasac000
@image{cvtool-example-nasac000,10cm}
@caption{2D image "Nasa"}
@end float

@float Figure,Figure nasad000
@image{cvtool-example-nasad000,10cm}
@caption{Simplistic depth map for 2D image "Nasa"}
@end float

@subsection Depth Image Based Rendering

For Depth Image Based Rendering, it is assumed that the given 2D image comes from a "middle" 
camera. The left and right views of virtual left and right cameras are then computed from this
middle view and the depth map:
@example
$ cvtool dibr -d nasad000.pgm -b 8 \
  < nasac000.ppm > nasac000-stereo.ppm
@end example
The parameter @var{b} specifies the distance between the virtual left and right
cameras, in pixels.

To compute the left and right view, objects have to be moved to left and right.
No information is available about the background that becomes visible when
moving a near object.  This causes disocclusion holes in the left and right
view.  These holes are normally filled with a simple average color technique.
To make them visible, use the option @code{--hole-filling=none}.

Disocclusion holes always degrade the image quality in comparison to the
original middle view.  To reduce the size of these holes, a moderate smoothing
filter is usually applied to the depth maps before depth image based rendering.
While this further reduces the accuracy of the depth maps, it improves the
viewing experience.
@example
$ cvtool smooth gauss -k 3 \
  < nasad000.pgm > nasad000-smoothed.pgm
$ cvtool dibr -d nasad000-smoothed.pgm -b 8 \
  < nasac000.ppm > nasac000-stereo.ppm
@end example

@subsection Viewing the result

The file @code{nasac000-stereo.ppm} now contains the left and right view side by side.
The @code{stereoview} command can be used to prepare this image pair for display on 
different devices. Currently, anaglyph glasses (red-blue, red-green, red-cyan) and 
autostereoscopic monitors from @url{http://www.dti3d.com/,DTI} are supported.

The following command produces a single image that can be viewed with red-cyan anaglyph
glasses:
@example
$ cvtool color -g 1.4 < nasac000-stereo.ppm \
  | cvtool stereoview anaglyph -c --glasses red-cyan \
  > nasac000-stereo-redcyan.ppm
@end example

@node Creating a stereoscopic video from a 2D video
@section Creating a stereoscopic video from a 2D video

The only difference between creating stereoscopic images, as explained in the
previous section @ref{Creating a stereoscopic image from a single 2D image},
and creating stereoscopic videos is that you have many 2D video frames and need
a depth map for each of them.

One way to get these depth maps is a camera with a real-time depth sensor, but most 
people don't have one of these. Depth data is sometimes available for computer generated
videos. For example, it is possible to modify the Quake3 sources to save depth data
when recording demo videos. See @url{http://www.marlam.de/Q3-stereoscopic-videos-based-on-depthmaps-HOWTO.txt}
for instructions on this.

@subsection Depth Tracking

Most of the time, however, the 2D video is all that is available, and manually creating
depth maps for every single frame is not an option.
In these situations, depth tracking is used: starting from few initial depth maps, the
rest is computed by tracking the depth of objects as they move around in the video scene.

The requirements for this are:
@itemize
@item A video scene that does not change too much, so that most objects can be tracked from the
first to the last frame.
@item A motion estimation method
@item A few initial depth maps
@end itemize

As an example, we use the Nasa video scene 
@url{http://spaceflight.nasa.gov/gallery/video/shuttle/sts-114/qtime/114_fdh05_clip3.mov}
from which the example in the previous section was taken.

First, we convert the video to YUV4MPEG2 format. Then, we extract frames 800-1250 with the 
@code{select} command of cvtool. The result is saved to @code{nasa.y4m}.

The motion estimation in both forward and backward direction is done with the commands
@example
$ cvtool opticalflow bm-sad    -k 8 -M 5 -D 0.01 -L 0.5 \
  < nasa.y4m > flow-fw.txt
$ cvtool opticalflow bm-sad -b -k 8 -M 5 -D 0.01 -L 0.5 \
  < nasa.y4m > flow-bw.txt
@end example
Beware: this can take up to several hours to compute! Better get some sleep in the meantime.

Initial depth maps are manually created for the first, middle, and last frame, and saved to 
the files @code{nasad000.pgm}, @code{nasad225.pgm}, and @code{nasad450.pgm}.
The result is shown in @ref{Figure nasacd000225450}.

@float Figure,Figure nasacd000225450
@noindent
@image{cvtool-example-nasac000,8cm}@image{cvtool-example-nasad000,8cm}

@noindent
@image{cvtool-example-nasac225,8cm}@image{cvtool-example-nasad225,8cm}

@noindent
@image{cvtool-example-nasac450,8cm}@image{cvtool-example-nasad450,8cm}
@caption{Frames 0, 225, and 450 of the "Nasa" video scene, and the manually created depth maps.}
@end float

No we have everything that is necessary for depth tracking. The following
command will produce a series of depth maps for frames 0-450 of the video:
@example
$ cvtool trackdepth -n 451 -d 0,225,450 -f flow-fw.txt -F flow-bw.txt \
  nasad000.pgm nasad225.pgm nasad450.pgm > nasad.pgm
@end example
If you view the resulting depth maps as a video, you will notice some errors in the tracking
of objects. Nevertheless, the stereoscopic video created with this sloppy depth data will
be OK!

Now we can use the same commands to produce a stereoscopic video for anaglyph glasses as in the
previous section @ref{Creating a stereoscopic image from a single 2D image}:
@example
$ cvtool smooth gauss -k 3 \
  < nasad.pgm > nasad-smoothed.pgm
$ cvtool dibr -d nasad-smoothed.pgm -b 8 \
  < nasa.y4m > nasa-stereo.y4m
$ cvtool color -g 1.4 < nasa-stereo.y4m \
  | cvtool stereoview anaglyph -c --glasses red-cyan \
  > nasa-stereo-redcyan.y4m
@end example

The key to good depth tracking results is good per-pixel motion
estimation, and this is still a very problematic field. You're invited to write
a reliable and fast motion estimator for cvtool!

The following script summarizes all necessary steps:
@example
@verbatiminclude cvtool-example-nasa-script.sh
@end example

@node Enhancing cvtool
@chapter Enhancing cvtool

Adding new commands to cvtool should be easy. Please look into the subdirectory
@command{cvtool} in the source distribution. Every command is in its own file, and
needs only to be registered in @file{cvtool.c} and @file{Makefile.am}. 

For example, the command @command{foo} must be defined in a file @file{cmd_foo.c}.
It must provide two functions: @code{void cmd_foo_print_help(void)}, which will be called
when the user types @command{cvtool help foo} and should print a short help message,
and @code{int cmd_foo(int argc, char *argv[])} which implements the command and
should behave just like the @code{main} function of a standalone C program.

The following macro adds the function declarations to @file{cvtool.c}: 
@code{COMMAND_DECL(foo)}. The following macros adds the function to the list of known
commands: @code{COMMAND(foo)}. Both macros should be inserted into the existing lists in
ascending alphabetical order.

Finally, automake must know about the new file, so @code{cmd_foo.c} must be added to 
@code{cvtool_SOURCES} in Makefile.am.

Simple existing commands such as @code{cmd_flip.c} or @code{cmd_cut.c} can serve 
as examples on how to use CVL features and the @code{cvtool_getopt()} function defined
in @file{option.[ch]}.

Once the new command works, a test script @file{cmd_foo.sh} should be added to the 
@file{tests} subdirectory (look at the existing scripts for examples), and the 
complete documentation of the command should be added to @file{doc/cvtool.texi}.


@node Command index
@appendix Command index
@menu
* Command index
@end menu

@printindex cm


@bye
