\input texinfo   @c -*-texinfo-*-
@afourpaper
@setfilename cvtool.info
@set UPDATED October 25, 2006
@set UPDATED-MONTH October 2006
@set EDITION 0.1.0
@set VERSION 0.1.0
@settitle cvtool @value{VERSION}

@c Define new index for commands
@defcodeindex cm

@finalout
@copying
This manual was last updated @value{UPDATED} for version
@value{VERSION} of cvtool.

Copyright @copyright{} 2005, 2006 Martin Lambers

@quotation
This program, including this manual, is free software; you can redistribute it
and/or modify it under the terms of the GNU General Public License as published
by the Free Software Foundation; either version 2 of the License, or (at your
option) any later version.

This program, including this manual, is distributed in the hope that it will be
useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
Public License for more details.

You should have received a copy of the GNU General Public License along with
this program and manual; if not, write to the Free Software Foundation, Inc.,
51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
@end quotation
@end copying

@dircategory Individual utilities
@direntry
* cvtool: (cvtool).	A computer vision tool.
@end direntry

@titlepage
@title cvtool
@subtitle A computer vision tool
@subtitle version @value{VERSION}, @value{UPDATED}
@author Martin Lambers (@email{marlam@@marlam.de})
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@contents

@ifnottex
@node Top
@top cvtool
@insertcopying
@end ifnottex

@menu
* Overview::
* Commands::
* Examples::
* Enhancing cvtool::
* Command index::
@end menu


@node Overview
@chapter Overview

@menu
* Concept::
* Supported file types::
* Output::
* Global options::
* Common parameters::
* Environment::
* Exit codes::
@end menu

@node Concept
@section Concept

Cvtool is a filter that manipulates one or more images: it reads images from
standard input and writes the manipulated images to standard output. It can
read and write streams of NetPBM images (ppm, pgm, pbm) and video streams in
the YUV4MPEG2 format used by the MJPEG Tools.

Cvtool integrates all its functionality into a single binary, and makes
it available through commands such as @code{rotate}, @code{filter}, and 
others.

The following command scales a NetPBM image by a factor of 3:
@example
$ cvtool scale --factor 3.0 < input.ppm > output.ppm
@end example

This is how one would select a rectangle from a YUV4MPEG2 video stream:
@example
$ cvtool cut --left 10 --top 10 --width 100 --height 100 \
  < input.y4m > output.y4m
@end example

@code{cvtool help} prints a list of available commands, and 
@code{cvtool help cmd} prints help for the command @code{cmd}.


@node Supported file types
@section Supported file types

@subsection NetPBM formats: @samp{pnm}

All NetPBM image formats (pbm, pgm, ppm, pam) are supported, except for their
old "plain" variants. Multiple images in one file are supported. They may
differ in size and type.

Cvtool always uses 256 values per color channel. If the input uses a different
number, it will be converted, and a warning will be issued.

@subsection YUV4MPEG2 format: @samp{y4m}

Cvtool supports a subset of the YUV4MPEG2 format as used by MJPEG Tools.

The following features are not yet supported:
@itemize
@item Chroma subsampling other than 420jpeg and 444
@item X-tags for streams
@item X-tags for frames
@item Interlacing
@end itemize

Internally, cvtool works with chroma information for each pixel. This
corresponds to the 444 chroma subsampling type of the YUV4MPEG2 format.  The
420jpeg subsampling type stores chroma information only for groups of 4 pixels,
which may mean a loss of information.

Cvtool will keep the chroma type of the input files, which is 420jpeg in most cases, 
and it will use the 420jpeg type by default when creating new @samp{y4m} streams.
This is because many tools, including mpeg2enc and MPlayer, only accept 420jpeg subsampling.

To preserve the full chroma information across several stream manipulation
steps, the 444 subsampling must be requested explicitly, for example with the
convert command:
@example
$ cvtool convert --chroma 444 < input.y4m \
  | ... manipulate frames ... \
  | cvtool convert --chroma 420jpeg \
  | mpeg2enc -f4 -o video.mpg
@end example

@node Output
@section Output

Cvtool normally prints messages to @code{stderr}. It prepends messages with its
name, the level of information, and the name of the command.

The level of information is @code{DBG} for debugging messages, @code{INF} for
informational messages, @code{WRN} for warnings, @code{ERR} for error
messages, and @code{REQ} for requested information. Normally, cvtool prints only 
messages of level @code{INF} or higher, but this can be changed with 
@option{--quiet} and @option{--verbose}; see below.

Some commands, for example @command{info}, print special information messages
that the user explicitly requests. Such special messages have the level
@code{REQ}, and can usually be redirected using the @option{--output} option.
In this case, no additional information will be prepended to the messages.

The special filename @code{-} means standard output (@code{stdout}).
Redirecting messages to @code{stdout} is only allowed when no images are
written to @code{stdout}.


@node Global options
@section Global options

@table @code
@item -q|--quiet
Reduces the amount of output: only messages with level @code{WRN} 
and higher will be printed.

@item -v|--verbose
Increases the amount of output: all messages will be printed, even those
with level @code{DBG}. This will include progress information in many
cases, but much of the output is really only useful for debugging purposes.
@end table

@node Common parameters
@section Common parameters

@subsection Arrays and Matrices

Some commands need arrays of integer or floating point values as parameters.
Matrices are treated as two-dimensional arrays. Higher dimensions are also
possible.

All of these array types are treated the same: the first part of the argument
determines the number of dimensions of the array and its size in each
dimension. The second part lists all values, separated by commas.

If the command requests an array or matrix of fixed dimension and size (or of
dimension 1 and arbitrary size), then the first part can be omitted: only the
value list is necessary in this case.

Examples:
@itemize
@item An array with three integer values
@example
3:1,1,1
@end example
@item An array with five floating point values
@example
5:1.2,1.3,0.7,0.5,0.0
1.2,1.3,0.7,0.5,0.0
@end example
@item A 3x3 matrix array with integer values
@example
3x3:1,2,3,4,5,6,7,8,9
@end example
@item A three-dimensional array with floating point values
@example
2x2x2:1.11,1.12,1.21,1.22,2.11,2.12,2.21,2.22
@end example
@end itemize

@subsection Colors

Colors can be given in one of three forms:
@enumerate
@item X11 color names@*
X11 comes with a file rgb.txt that defines names for lots of colors.  Cvtool
accepts each of these names, case insensitively.  The full list can be found
here: @url{http://cvs.freedesktop.org/*checkout*/xorg/xc/programs/rgb/rgb.txt}.
@item Hex triplets@*
The RGB components of a color can be specified directly as a hex triplet:
@code{0xrrggbb}.  For example, @code{0x00ff00} is green, @code{0xffffff} is
white, and @code{0x000000} is black.
@item Decimal values@*
The RGB components of a color can be specified as decimal values, prepended
with r, g, or b.  For example, @code{g255} is green (the red and blue
components default to zero), @code{r255g255b255} is white, and @code{r0g0b0} is
black.
@end enumerate

@node Environment
@section Environment

@table @env
@item TMPDIR
Directory to create temporary files in.
@item COLUMNS
Cvtool tries to format its messages so that they do not use more than the given number of columns. 
If this variable is unset, a default of 80 will be used.
@end table

@node Exit codes
@section Exit codes

Cvtool returns @code{0} on success and @code{1} on error.


@node Commands
@chapter Commands

@menu
* Informational commands::
* Stream manipulation::
* Resizing frames::
* Transforming frames::
* Mixing frames::
* Color manipulation::
* Drawing::
* Filtering frames::
* Detecting image features::
* Image analysis::
* Comparing frames::
* Stereoscopic image pairs::
* Miscellaneous::
@end menu

@node Informational commands
@section Informational commands

@menu
* help::
* version::
* info::
@end menu

@node help
@subsection help
@cmindex help
@code{help [@var{command}]}

@noindent
Print general or command specific help.

@node version
@subsection version
@cmindex version
@code{version}

@noindent
Print version information.

@node info
@subsection info
@cmindex info
@code{info [-o|--output=@var{file}]}

@noindent
Print information about the first frame in a stream.

The information is printed to stderr or to the given file ('-' means stdout).

The following information will be printed: @code{STREAMTYPE} (@samp{y4m} or
@samp{pnm}), @code{PIXELTYPE} (@samp{yuv} for @samp{y4m} streams, @samp{rgb} or
@samp{gray} for @samp{pnm} streams), @code{WIDTH}, @code{HEIGHT}, and, if
@code{STREAMTYPE} is @samp{y4m}, @code{CHROMA}, @code{INTERLACING},
@code{FRAMERATE}, @code{ASPECTRATIO}.

In a @samp{y4m} stream, all frames are of the same type, and the information
thus applies to the whole stream. This is not true for @samp{pnm} streams!

@example
$ cvtool info < file.pnm
cvtool: [INF] info: STREAMTYPE=pnm PIXELTYPE=rgb WIDTH=352 HEIGHT=240
$ eval `cvtool info -o - < file.pnm`
$ echo $WIDTH
352
@end example


@node Stream manipulation
@section Stream manipulation

@menu
* combine::
* convert::
* create::
* foreach::
* merge::
* reverse::
* select::
* split::
@end menu

@node combine
@subsection combine
@cmindex combine
@code{combine [-m|--method=(lr|leftright)|(tb|topbottom)]
[-j|--justify=(left|top)|center|(right|bottom)] [-c|--color=@var{color}]
@var{file@dots{}}}

@noindent
Combine the given files by placing the frames side by side (@samp{leftright})
or one below the other (@samp{topbottom}).

The default is @samp{leftright}. If the frames have different sizes, then the
smaller ones have to be aligned with the biggest one. The default is to center
them. The remaining space will be filled with the given color; the default is
black.

@example
$ cvtool combine left.pnm right.pnm > lr.pnm
$ cvtool combine -m tb \
  <(cvtool combine a.pnm b.pnm) \
  <(cvtool combine c.pnm d.pnm) \
  > 2x2.pnm
@end example

@node convert
@subsection convert
@cmindex convert
@code{convert [-o|--output-type=pnm|y4m] [-g|--gray] [-C|--chroma=420jpeg|444]
[-F|--framerate=@var{f1:f2}] [-A|--aspect-ratio=@var{a1:a2}]}

@noindent
Convert input to @samp{pnm} or @samp{y4m} format. 

The default is to keep the input format.

The @option{--gray} option converts each frame to graylevels. For the @samp{pnm}
output type, this is the only option that has any effect; the others are
silently ignored.

For @samp{y4m}, the chroma subsampling, frame rate, and aspect ratio can be
given. The default is to incur them from the input stream. If the input 
stream is not a @samp{y4m} stream, the defaults are @samp{0:0} ("unknown") 
for frame rate and aspect ratio, and @samp{420jpeg} for chroma subsampling.

@example
$ cvtool convert -C 444 < in.y4m > out.y4m 
$ cvtool convert -o pnm < video.y4m > video.pnm
@end example

@node create
@subsection create
@cmindex create
@code{create [-t|--type=gray|rgb|yuv] [-n|--n=@var{n}] -w|--width=@var{w}
-h|--height=@var{h} [-c|--color=@var{color}] [-C|--chroma=420jpeg|444]
[-F|--framerate=@var{f1:f2}] [-A|--aspect-ratio=@var{a1:a2}]}

@noindent
Create a stream of frames.

@var{n} (default 1) frames of pixel type @samp{gray}, @samp{rgb} or @samp{yuv}
(default @samp{rgb}) are created with the given width and height and filled
with the given color (default black). 

The resulting stream type will be @samp{pnm} for @samp{gray} and @samp{rgb}
frames, and @samp{y4m} for @samp{yuv} frames. The chroma subsampling, frame
rate, and aspect ratio information is only relevant for the @samp{yuv} type; it
will be silently ignored for the other types.

@example
$ cvtool create -t yuv -F 25:1 -w 720 -h 576 -n 250 > 10-seconds-PAL.y4m
$ cvtool create -t rgb -w 720 -h 576 -c green > green.pgm
@end example

@node foreach
@subsection foreach
@cmindex foreach
@code{foreach [-s|--shell=@var{shell}] [-n|--n=@var{n}] @var{cmd}}

@noindent
Execute the given command for every frame. 

The command is expected to read @var{n} frames from standard input (default is
@var{n}=1), and write an arbitrary number (including zero) of frames to
standard output. The original frame(s) that were given to the command are
replaced by the output of the command. The frames that the command produces are
converted to the format of the original frames. The foreach command replaces
the following special strings in the command @var{cmd} before executing the
command: @code{%N} (replaced with frame number), @code{%W} (replaced with frame
width), and @code{%H} (replaced with frame height). If @var{n} is greater than
1, these values refer to the first frame that is piped to the command.  The
command @var{cmd} is executed by passing it to the system shell.  The default
is @samp{/bin/sh -c} on most systems. This can be overridden with the
@option{--shell} option. It expects a string with zero or one spaces: The first
part of the string is the shell, the second part (if any) is the first option
to the shell. The next option will then be the command to execute.

@example
$ cvtool foreach 'cvtool info' < many-images.pnm
# Rotate a video. Use chroma 444 to allow odd width/height. Resize after 
# rotation to keep the original dimensions.
$ cvtool convert -C 444 < video.y4m \
  | cvtool foreach 'cvtool rotate -a %N | cvtool resize -w 352 -h 240' \
  | cvtool convert -C 420jpeg \
  > rotating-video.y4m
@end example

@node merge
@subsection merge
@cmindex merge
@code{merge [-s|--shuffle] [-o|--output=@var{file}] @var{file@dots{}}}

@noindent
Merges files into one stream, in the given order.

If @code{--shuffle} is used, the order will be randomized. The file names will
be printed to stderr in the order they are merged. If @code{--output} is used,
the file names will be written to the given file instead.

@example
$ ls
frame000.pnm frame001.pnm frame002.pnm
$ cvtool merge * | cvtool convert -o y4m > video.y4m
@end example

@node reverse
@subsection reverse
@cmindex reverse
@code{reverse}

@noindent
Reverses the order of the frames in the stream.

This requires a temporary file that is big enough to hold the complete input
stream.

@example
$ cvtool reverse < video.y4m > oediv.y4m
@end example

@node select
@subsection select
@cmindex select
@code{select [-d|--drop] @var{range@dots{}}}

@noindent
Selects frames from a stream.

By default, frames in the given ranges are kept and all others dropped. With
@code{--drop}, frames in the given ranges are dropped and all others kept.

A range must be of the following form: @var{l}-@var{h} (from @var{l} to
@var{h}), -@var{h} (from beginning to @var{h}), @var{l}- (from @var{l} to end),
@var{l} (only @var{l}), or - (everything).  Each start and end point can be a
frame number (counting from 0) or a time in the format
[hours:]minutes:seconds[.fraction]. In short: if it contains a colon, it's a
time. Time ranges can only be used for YUV4MPEG2 streams with known frame rate.
IMPORTANT: If you use frame number ranges, the high frame number is inclusive:
the frame with this number will be dropped/kept. If you use time ranges, the
high time is exclusive and marks the first frame that will not be dropped/kept.

@example
# Drop the frames 0 to 124 from the stream (with a framerate of 25 fps,
# these are the first five seconds).
$ cvtool select --drop 0-124 < in.y4m > out.y4m

# Drop the first 5 seconds of the stream (with a framerate of 25 fps,
# these are the frames 0 to 124. The frame at 0:05, with the frame 
# number 125, will be the first that is kept!)
$ cvtool select --drop 0:00-0:05 < in.y4m > out.y4m

# Keep the second 5-minutes-block and drop all the rest. Both 
# commands are equivalent.
$ cvtool select 5:00-10:00 < in.y4m > out.y4m
$ cvtool select --drop -5:00 10:00- < in.y4m > out.y4m
@end example

@node split
@subsection split
@cmindex split
@code{split [-n|--n=@var{n}] [-t|--template=@var{template}] [-b|--backwards]
[-s|--start=@var{i}]}

@noindent
Split the input stream into multiple files.

Each new files contains @var{n} frames (default is @var{n}=1). The filename
will be generated from the template: the template must contain exactly one
appearance of the character @code{%}. This character must be followed by one of
the digits @code{1} through @code{9}. The digit must be followed by the
uppercase character @code{N}. This special string @code{%xN} will be replaced
by the number of the first frame of the stream contained in this file. The
number will be left-padded with zeros until its width is at least @code{x}
characters. The default template is @samp{frame-%6N}.  A start number i for the
first frame can be given, and the frames can be counted backwards. If the
frames are counted backwards, a start number is required, because negative
frame numbers are not accepted.

@example
$ cvtool split -t frame%3N.pnm < ../video.y4m
$ ls
frame000.pnm frame001.pnm frame002.pnm
$ cvtool split -s 99 -b -t img%2N.pnm < ../video.y4m
$ ls
img99.pnm img98.pnm img97.pnm
@end example


@node Resizing frames
@section Resizing frames

@menu
* resize::
* cut::
@end menu

@node resize
@subsection resize
@cmindex resize
@code{resize -w|--width=@var{w} -h|--height=@var{h} [-x|--x-offset=@var{x}]
[-y|--y-offset=@var{y}] [-c|--color=@var{color}]}

@noindent
Resize the frames to the given new width and height.

Place the original frame contents at the position (@var{x},@var{y}) relative to
the new frame (these offsets may be negative). If no or an incomplete position
is given, compute the missing part(s) so that the old contents are centered on
the new frame. Fill holes that might result with the given color (default is
black).

@example
$ cvtool info < img.pnm
cvtool: [INF] info: STREAMTYPE=pnm PIXELTYPE=rgb WIDTH=352 HEIGHT=240
# Add a green border of 10 pixels
$ cvtool resize -w 372 -h 260 -c green < img.pnm > img2.pnm
@end example

@node cut
@subsection cut
@cmindex cut
@code{cut -l|--left=@var{l} -t|--top=@var{t} -w|--width=@var{w}
-h|--height=@var{h}}

@noindent
Only let the given rectangle through; cut the rest of each frame.

@example
$ cvtool cut -l 0 -t 0 -w 10 -h 10 < in.pnm > out.pnm
@end example


@node Transforming frames
@section Transforming frames

@menu
* affine::
* flip::
* flop::
* rotate::
* scale::
* shear::
@end menu

@node affine
@subsection affine
@cmindex affine
@code{affine -m|--matrix=@var{2x2-matrix} [-c|--color=@var{color}]
[-i|--interpolation=none|bilinear]}

@noindent
Apply the affine tranformation defined by the given matrix (4 floating point
values separated by commas) to the frames.  The frame dimensions will be
adapted so that the resulting image will fit. Possible holes will be filled
with the given color; the default is black. The default interpolation type is
bilinear.

@example
$ cvtool affine -m 2.0,0.1,0.75,1.0 < in.pnm > out.pnm
@end example

@node flip
@subsection flip
@cmindex flip
@code{flip}

@noindent
Flip frames (left/right).

@example
$ cvtool flip < in.pnm > out.pnm
@end example

@node flop
@subsection flop
@cmindex flop
@code{flop}

@noindent
Flop frames (top/bottom).

@example
$ cvtool flop < in.pnm > out.pnm
@end example

@node rotate
@subsection rotate
@cmindex rotate
@code{rotate -a|--angle=@var{angle} [-c|--color=@var{color}]
[-i|--interpolation=none|bilinear]}

@noindent
Rotate frames with the given angle (in degrees), counterclockwise.

The dimensions of the rotated frame will be big enough to hold all informations
from the source.  "Holes" will be filled with the given color; the default is
black. The default interpolation type is bilinear (simple rotations (90, 180,
or 270) do not need interpolation).

@example
$ cvtool rotate -a -45 < in.pnm > out.pnm
@end example

@node scale
@subsection scale
@cmindex scale
@code{scale [-w|--width=@var{w}] [-h|--height=@var{h}]
[-i|--interpolation=none|bilinear]}@*
@code{scale -x|--factor-x=@var{factor-x} -y|--factor-y=@var{factor-y}
[-i|--interpolation=none|bilinear]}@*
@code{scale -f|--factor=@var{factor} [-i|--interpolation=none|bilinear]}

@noindent
Scale frames to new size. 

The default interpolation type is bilinear.

First form: Give new width and/or height. If one value is missing, it is
computed from the other so that the aspect ratio remains the same.

Second form: Give scale factors for width and height.

Third form: Give one scale factor for both width and height.

@example
$ cvtool info < in.pnm
cvtool: [INF] info: STREAMTYPE=pnm PIXELTYPE=rgb WIDTH=400 HEIGHT=200
# The following three commands do the same:
$ cvtool scale -w 100 -h 50    < in.pnm > out.pnm
$ cvtool scale -x 0.25 -y 0.25 < in.pnm > out.pnm
$ cvtool scale -f 0.25         < in.pnm > out.pnm
@end example

@node shear
@subsection shear
@cmindex shear
@code{shear [-x|--shear-x=@var{angle-x}] [-y|--shear-y=@var{angle-y}]
[-c|--color=@var{color}] [-i|--interpolation=none|bilinear]}

@noindent
Shear frames in horizontal and/or vertical direction.

The frames are sheared with the given angle(s) from (-90,90).  Negative angles
shear clockwise. "Holes" will be filled with the given color; the default is
black. The default interpolation type is bilinear.

@example
$ cvtool shear -x 20 -y 10 < in.pnm > out.pnm
@end example


@node Mixing frames
@section Mixing frames

@menu
* blend::
* layer::
@end menu

@node blend
@subsection blend
@cmindex blend
@code{blend -s|--source=@var{file} [-a|--alpha=@var{file}] [-S|--single]
[-x|--x=@var{x}] [-y|--y=@var{y}]}

@noindent
Blends the source into the image stream, using an alpha map.

With no alpha map, the source is simply copied into the images. @var{x} and
@var{y} specify the position that the source should be copied to. The default
is (0,0). Positions outside of the images are possible: parts of the source
that do not fit into the images will be ignored. When @option{--single} is
used, only the first frame of the source will be used; this frame will be
copied into all images of the stream.

@example
$ cvtool blend --single -s logo.pnm -a logo-alpha.pgm -x 700 -y 0 \
  < video.y4m > video-with-logo.y4m
@end example

@node layer
@subsection layer
@cmindex layer
@code{layer -m|--mode=min|max|median|or|and|xor|diff|add|xadd|sub|xsub|mul|div file@dots{}}

@noindent
Layers the frames from the given files on top of each other, using the given
mode.  

Layering will be done for each channel separately. Graylevel frames have
only one channel. Color frames have the channels R, G, and B. Graylevel
layering is only done if all input frames are graylevel. The input frames may
differ in size. In this case, the result will be big enough to hold all input
frames, and the input frames are centered on the result.

The modes are as follows:
@itemize
@item @code{min}: Use minimum value.
@item @code{max}: Use maximum value.
@item @code{median}: Use median value.
@item @code{or}: Bitwise or.
@item @code{and}: Bitwise and.
@item @code{xor}: Bitwise xor.
@item @code{diff}: Use difference between maximum and minimum value.
@item @code{add}: Use sum of values.
@item @code{xadd}: Use sum of values. The ranges are transformed so that the
results fit in [0,255]. Example for two layers: X = (A/2) + (B/2).
@item @code{sub}: Subtract values from the first value.
@item @code{xsub}: Subtract values from the first value. The ranges are
transformed so that the results fit in [0,255]. Example for two layers: X =
(A/2) - (B/2) + 255/2.
@item @code{mul}: Multiply values.
@item @code{div}: Divide values.
@end itemize

@example
$ cvtool layer --mode=or red.pnm green.pnm blue.pnm \
  > allchannels.pnm
@end example

@node Color manipulation
@section Color manipulation

@menu
* binarize::
* channel::
* color::
* equalize::
* invert::
@end menu

@node binarize
@subsection binarize
@cmindex binarize
@code{binarize global -t|--threshold=@var{t}}@*
@code{binarize iterative}@*
@code{binarize otsu}@*
@code{binarize hysterese -l|--low=@var{l} -h|--high=@var{h}}@*
@code{binarize local -T|--type=mean|median|minmax -k|--k=@var{k}
-C|--constant=@var{C}}

@noindent
Convert input to grayscale (if necessary), then binarize it using the given
method.

The global method turns every pixel to black whose value is lower than the
given threshold; all over pixels are turned to white. The threshold must be
from [0,256].

The iterative and otsu methods are global methods, too, but they compute the
threshold automatically.

The hysterese method is not adequate for general images; it is mainly used by
the Canny edge detector. It uses a low and a high threshold; both must be in
[0,255], and should be chosen so that 2@var{l} <= @var{h} <= 4@var{l}.

The local method uses a local threshold (@var{T}-@var{C}) for a neighborhood of
size (2@var{k}+1)x(2@var{k}+1), where @var{T} is the mean of all pixel values
in the neighborhood, the median of the pixel values, or the mean of the minimum
and maximum of the pixel values. @var{C} can be negative. The mean type is much
faster than median and minmax.

@example
$ cvtool binarize local -T median -k 5 -C 20 < gray.pgm > bw.pgm
@end example

@node channel
@subsection channel
@cmindex channel
@code{channel [-r|--reverse] -c|--channel=r|g|b}

@noindent
Interpret the input frames as RGB frames, extract the given channel, and write
it into gray frames. When @option{--reverse} is used, the input is interpreted
as graylevel frames, and then converted to RGB frames by copying the graylevel
values into the given channel and setting the other two channels to zero.

@example
$ cvtool channel -c r < color.ppm > red.pgm
$ cvtool channel -r -c r < red.pgm > color-red-only.ppm
@end example

@node color
@subsection color
@cmindex color
@code{color [-h|--hue=@var{h}] [-s|--saturation=@var{s}]
[-l|--lightness=@var{l}] [-c|--contrast=@var{c}]
[-g|--gamma=(@var{g}|@var{gr},@var{gg},@var{gb})]}

@noindent
Color adjustment.

Hue, saturation, lightness, and constrast are manipulated in the HSL (Hue,
Saturation, Lightness) color space. @var{h} is an additive constant to the hue
angle, in degrees. @var{s}, @var{l}, @var{c} measure the relative change in
saturation, lightness, contrast: -1 means the result will be zero, 0 means the
result will be the same as the original, and +1 means that the result will be
two times as high as the original. Values greater than +1 are possible. For
example, s = -1 will convert the input images to graylevels. See the
@url{http://en.wikipedia.org/wiki/HLS_color_space,Wikipedia entry for HSL color
space} for more information.

Gamma correction (option @option{--gamma} is applied to the gray channel for
@samp{gray} frames, to the Y channel for @samp{yuv} frames, and to the R,G,B
channels for @samp{rgb} frames.  If three gamma values are given, the frames
are always converted to @samp{rgb}, then gamma corrected for each channel
separately, and then converted back to their original type. All gamma values
must be greater than zero. Values greater than 1.0 lighten the image, values
smaller than 1.0 darken them.

@example
$ cvtool color -h 120 < red.pnm > green.pnm
$ cvtool color -h 120 < green.pnm > blue.pnm
$ cvtool color -h 120 < blue.pnm > red.pnm
$ cvtool color -s -1 < colored.pnm > gray.pnm
$ cvtool color -l +1 < dark.pnm > light.pnm
$ cvtool color --gamma 1.4 < dark.pnm > light.pnm
@end example

@node equalize
@subsection equalize
@cmindex equalize
@code{equalize}

@noindent
Equalize Histogram. 

Color images are equalized in the Y part of the YUV color space.

@example
$ cvtool equalize < in.pnm > out.pnm
@end example

@node invert
@subsection invert
@cmindex invert
@code{invert}

@noindent
Invert input frames.

@example
$ cvtool invert < in.pnm > out.pnm
@end example


@node Drawing
@section Drawing

@menu
* draw::
@end menu

@node draw
@subsection draw
@cmindex draw
@code{draw 
[-w|--width=@var{width}] 
[-d|--dash=@var{dash-specification}] 
[-l|--line-cap=butt|round|square] 
[-L|--line-join=miter|round|bevel] 
[-s|--border-style=none|color|pattern|multipattern|linear-gradient|radial-gradient]
[-c|--border-color=@var{color}] 
[-p|--border-pattern=@var{file}] 
[-g|--border-gradient=@var{gradient-specification}] 
[-S|--fill-style=none|color|pattern|multipattern|linear-gradient|radial-gradient]
[-C|--fill-color=@var{color}] 
[-P|--fill-pattern=@var{file}]
[-G|--fill-gradient=@var{gradient-specification}]
[-f|--font-family=@var{font}] 
[-t|--font-slant=normal|italic|oblique] 
[-W|--font-weight=normal|bold] 
[-F|--font-size=@var{size}|@var{size-x},@var{size-y}] 
[-j|--justify-x=left|right|center] 
[-J|--justify-y=bottom|top|center] 
[-a|--antialias] 
[-u|--unit]
@var{command@dots{}}}

@noindent
Draw simple geometric forms, lines and curves, and/or text.

The style for the object lines and the filling can be specified separately; it
is either @samp{none} (line/filling is not drawn), @samp{color} (solid color),
@samp{pattern} (a pattern read from a file), @samp{multipattern} (a different
pattern for each input frame, all read from a file), @samp{linear-gradient} (a
linear gradient), or @samp{radial-gradient} (a radial gradient).  The default
is the solid color black for lines and no filling.

A linear gradient specification @code{x0,y0,color0,x1,y1,color1} defines a
gradient along the line from start point @code{x0,y0} (with color @code{color0}
to end point @code{x1,y1} (with color @code{color1}). Any number of additional
color stops can be added by appending an offset value and its associated color
to the gradient specification. The offsets must be between 0.0 and 1.0 and
describe the position on the gradient line, where 0.0 is the start point and
1.0 is the end point.

A radial gradient specification @code{x0,y0,r0,color0,x1,y1,r1,color1} defines
a gradient from the start cirlce @code{x0,y0,r0} with color @code{color0} to
the end circle @code{x1,y1,r1} with color @code{color1}. Additional stops can
be added in the same way as for linear gradients.

The style of lines can be further adjusted with the @option{--width},
@option{--dash}, @option{--line-cap}, and @option{--line-join} options. The
@option{--width} option selects the line width; it is 2.0 by default. The
@option{--dash} takes a list of values that specify alternating lengths for
"line on" and "line off" segments of a line. If only one value is given, these
lengths are equal.  The @option{--line-cap} option selects the style of line
and curve ends.  The @option{--line-join} options selects the style of the
meeting point of two line or curve segments.

Antialiasing can be turned on (default) and off with @option{--antialias}.

If @option{--unit} is given, then all coordinates and sizes on the command line
refer to a frame of size 1x1. All values are then scaled so that they match the
real frame dimensions. For example, the point (0.5,0.5) will always be in the
middle of a frame, regardless of the frame dimensions.

Text is drawn relative to the current drawing position (previously set with 
@code{move_to}, for example). By default, the current drawing position sets the
bottom left point of the first character of the text. This can be changed with
the @option{--justify-x} and @option{--justify-y} options. 
The font family, slant, weight, and size can be chosen. Note that you may not
get an error message if @option{--font-family} fails to set the given font,
because the underlying library may not report this error.  If you use two
values for the font size, then the first applies to the horizontal direction
and the second to the vertical direction, so that you can scale the font
asymmetrically.

A drawing command consists of a command name and parameter sets that define one
or more instances of the command.

Simple geometric forms:
@itemize @asis
@item @code{rectangle @var{topleft-x},@var{topleft-y},@var{width},@var{height} [@dots{}]}@*
Draw a rectangle.
@item @code{circle @var{center-x},@var{center-y},@var{radius} [@dots{}]}@*
Draw a circle.
@item @code{ellipse @var{rect-topleft-x},@var{rect-topleft-y},@var{width},@var{height} [@dots{}]}@*
Draw an ellipse in the given enclosing rectangle.
@item @code{arc @var{center-x},@var{center-y},@var{radius},@var{start-angle},@var{stop-angle}}@*
Draw a part of a circle, from the given start angle to the given stop angle.
@end itemize

Text:
@itemize @asis
@item @code{text @var{string}}@*
Print the string at the current drawing position.
@end itemize

Lines and curves:
@itemize @asis
@item @code{move_to @var{x},@var{y} [@dots{}]}@*
Move current point.
@item @code{line_to @var{x},@var{y} [@dots{}]}@*
Draw a line from the old current point to the new current point.
@item @code{curve_to @var{x0},@var{y0},@var{x1},@var{y1},@var{x2},@var{y2} [@dots{}]}@*
Draw a curve from the old current point to the new current point @var{x2},@var{y2}, Using
the control points @var{x0},@var{y0} and @var{x1},@var{y1}.
@item @code{rel_move_to @var{dx},@var{dy} [@dots{}]}@*
Move the current point using relative coordinates.
@item @code{rel_line_to @var{dx},@var{dy} [@dots{}]}@*
Draw a line using relative coordinates.
@item @code{rel_curve_to @var{dx0},@var{dy0},@var{dx1},@var{dy1},@var{dx2},@var{dy2} [@dots{}]}@*
Draw a curve using relative coordinates.
@item @code{close}@*
Close the currnet line/curve figure: draw a line from the current point to the start point of 
the figure and combine start and end point into one point.
@end itemize

Open lines and curves will automatically be closed when drawing geometric forms or text.

The draw command is only a simple interface to the excellent
@url{http://www.cairographics.org/,CAIRO} graphics library.  Much of the
@url{http://www.cairographics.org/documentation,CAIRO documentation} is useful
for this command, too, especially the @url{http://www.cairographics.org/FAQ,FAQ}.

@example
# Draw two green circles with a line width of 5.
$ cvtool draw -w 5 -c green circle 50,50,40 50,50,20 \
  < blank.pnm > circle.pnm
# The same, but filled with linear gradient from red to yellow to blue.
$ cvtool draw -w 5 -S linear-gradient \
  -G 10,50,red,90,50,blue,0.5,yellow circle 50,50,40 50,50,20 \
  < blank.pnm > circle.pnm
# Display one video inside another video in the form of a circle.
$ cvtool draw -s none -S multipattern -P video2.y4m circle 50,50,40 \
  < video1.y4m > out.y4m
# Print a string exactly centered in the middle of blank.pnm.
$ cvtool draw -u -f "Serif" -F 0.1,0.1 -j center -J center \
  move_to 0.5,0.5 text "Hello world" \
  < blank.pnm > text.pnm
@end example


@node Filtering frames
@section Filtering frames

@menu
* filter::
* convolve::
@end menu

@node filter
@subsection filter
@cmindex filter
@code{filter mean [-3|--3d] -k|--k=@var{k}}@*
@code{filter mean [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky}
[-t|--k-t=@var{kt}]}@*
@code{filter min [-3|--3d] -k|--k=@var{k}}@*
@code{filter min [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky}
[-t|--k-t=@var{kt}]}@*
@code{filter max [-3|--3d] -k|--k=@var{k}}@*
@code{filter max [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky}
[-t|--k-t=@var{kt}]}@*
@code{filter median [-3|--3d] -k|--k=@var{k}}@*
@code{filter median [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky}
[-t|--k-t=@var{kt}]}@*
@code{filter wallis [-3|--3d] -k|--k=@var{k} -m|--mean=@var{m}
-s|--stddev=@var{s} -g|--gain=@var{g} -r|--ratio=@var{r}}@*
@code{filter wallis [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky}
[-t|--k-t=@var{kt}] -m|--mean=@var{m} -s|--stddev=@var{s} -g|--gain=@var{g}
-r|--ratio=@var{r}}@*
@code{filter gauss [-3|--3d] -k|--k=@var{k}}@*
@code{filter gauss [-3|--3d] -x|--k-x=@var{kx} -y|--k-y=@var{ky}
[-t|--k-t=@var{kt}]}@*
@code{filter gauss [-3|--3d] [-k|--k=@var{k}] [-x|--k-x=@var{kx}]
[-y|--k-y=@var{ky}] [-t|--k-t=@var{kt}] [-s|--sigma=@var{s}]
[--sigma-x=@var{sx}] [--sigma-y=@var{sy}] [--sigma-t=@var{st}]}

@noindent
Filter frames, in 2D or 3D (with the third dimension being the
time).

The kernel size can be given for each dimension, or once for all. It will be
(2@var{kx}+1)x(2@var{ky}+1)[x(2@var{kt}+1)]. Different values for each
direction lead to asymmetric filtering. 

The gauss filter can be specified by the sigma value(s): the mask size will be
computed so that roughly 95% of the mass lies within the resulting mask. It is
also possible to specify both @var{sigma} and @var{k}.

The Wallis filter enhances contrast. Color images are processed in the
luminance component. Refer to the literature for a description of the parameters.

@example
$ cvtool filter gauss --3d -k 3 < video.y4m > smoothed-video.y4m
@end example

@noindent 
See also:
@itemize @asis
@item For the Wallis filter:@*
W.K. Pratt. @cite{Digital Image Processing.} 2nd edition, Wiley NY 1991, pp. 307-308.
@end itemize

@node convolve
@subsection convolve
@cmindex convolve
@code{convolve -K|--kernel=@var{K}}@*
@code{convolve -X|--vector-x=@var{X} -Y|--vector-y=@var{Y}
[-T|--vector-t=@var{T}]}

@noindent
Convolve frames with the given convolution kernel.

Both 2D and 3D kernels are accepted (the third dimension is the time). If the
kernel is separable, the vectors that generate it can be given instead, to
reduce computation costs. All kernel elements must be integers. The size of the
kernel must be an odd number in each dimension.

@example
# Both commands are equivalent to 2D smoothing with the 
# mean filter with k=1:
$ cvtool convolve -K 3x3:1,1,1,1,1,1,1,1,1 < in.pnm > out.pnm
$ cvtool convolve -X 3:1,1,1 -Y 3:1,1,1    < in.pnm > out.pnm
@end example


@node Detecting image features
@section Detecting image features

@menu
* edge::
@end menu

@node edge
@subsection edge
@cmindex edge
@code{edge sobel}@*
@code{edge canny -s|--sigma=@var{sigma} -l|--low=@var{l} -h|--high=@var{h}}

@noindent
Detect edges.

Sobel will generate graylevel images: the brighter a point, the stronger the
edge.

Canny will generate binary images. The @var{sigma} parameter is for Gauss
smoothing.  @var{l} and @var{h} are used for Hysterese thresholding; both must
be from [0,255].

@example
$ cvtool edge sobel < in.pgm > gray-edges.pgm
$ cvtool edge canny -s 1.2 -l 4 -h 8 < in.pgm > bw-edges.pgm
@end example


@node Image analysis
@section Image analysis

@menu
* opticalflow::
@end menu

@node opticalflow
@subsection opticalflow
@cmindex opticalflow
@code{opticalflow hs [-b|--backwards] -l|--lambda=@var{l}
-n|--iterations=@var{n}}@*
@code{opticalflow lk [-b|--backwards] -k|--k=@var{k}}@*
@code{opticalflow clg [-b|--backwards] -l|--lambda=@var{l} -O|--omega=@var{O}
-n|--iterations=@var{n}}@*
@code{opticalflow bm-sad [-b|--backwards] -k|--k=@var{k}
-M|--max-distance=@var{m} -D|--distance-weight=@var{dw}
-L|--luminance-weight=@var{lw}}@*
@code{opticalflow bm-asw [-b|--backwards] -k|--k=@var{k}
-M|--max-distance=@var{m} -c|--gamma-c=@var{gc} -p|--gamma-p=@var{gp}}@*
@code{opticalflow cc -t|--tolerance=@var{t} [-w|--warning-level=@var{w}]
[-o|--output=@var{file}] -f|--verification-flow=@var{file}}

@noindent
Compute the optical flow between frames. 

For @var{n} input frames, this command will produce @var{n}-1 fields of optical
flow vectors, in plain text format: the first will contain the optical flow
between the input frames 0 and 1, the second that between 1 and 2, and so
forth.

If the @code{--backwards} option is used, then the optical flow is computed in
the opposite direction: the first flow field will contain the optical flow
between frames 1 and 0, the second that between 2 and 1, and so forth.

The @emph{hs} (Horn/Schunck) method needs a regularisation parameter lambda
(try 10.0), and the number of iterations (try 50).

The @emph{lk} (Lukas/Kanade) method needs the neighborhood size
(2@var{k}+1)x(2@var{k}+1) as a parameter.

The @emph{clg} (Combined Local/Global) method needs a regularization parameter
lambda (try 10.0), a relaxation parameter omega for the iterative SOR method
(try 1.95; the value must be between 0 and 2), and the number of iterations
(try 50).

The @emph{bm-sad} (block matching with sum of absoulte differences) method
needs the block size (2@var{k}+1)x(2@var{k}+1) as a parameter, and the maximum
distance that matching blocks will be searched in. The cost of a block are (dw
\cdot distance + (1 - dw) \cdot average_pixel_difference). The maximum norm
distance is used here. Each pixel difference is calculated with (lw *
difference_in_luminance + (1 - lw) * difference_in_chrominance. The block with
the lowest cost is the match; it determines the optical flow in a given point.
Warning: This method is VERY SLOW!

The @emph{bm-asw} (block matching using adaptive support weights) method is a
block matching variant that uses special support weights for cost computation.
Try 12 for @var{k}, 7 for @var{gc} and 36 for @var{gp}. This implementation
uses a resolution pyramid to speed the process up and reduce uncertainty in
correspondence search.  Warning: This method is SLOW!

The @emph{cc} (consistency check) method does not compute optical flow from
images.  Instead, it offers the verification step that improves existing
optical flow fields: the flow fields from @code{stdin} are compared against
those from the given file.  Each flow vector in the first set of fields must
match its corresponding flow vector in the second set of fields with the given
tolerance. Vector pairs that differ by more than the given tolerance are marked
as unreliable, and are replaced by interpolations of neighboring reliable
vectors. If a warning level between 0 and 1 is given and the fraction of
unreliable vectors is greater than or equal to this level, then a warning is
issued for the current flow field pair.  These warnings can be redirected to a
separate file with the @code{--output} option.

@example
$ cvtool opticalflow bm-sad    -k 8 -M 5 -D 0.01 -L 0.5 \
  < video.y4m > flow-fw.dat
$ cvtool opticalflow bm-sad -b -k 8 -M 5 -D 0.01 -L 0.5 \
  < video.y4m > flow-bw.dat
$ cvtool opticalflow cc -t 2 -f flow-bw.dat \
  < flow-fw.dat > flow-fw-improved.dat
$ cvtool opticalflow cc -t 2 -f flow-fw.dat \
  < flow-bw.dat > flow-bw-improved.dat
@end example

@noindent 
See also:
@itemize @asis
@item For the @code{hs} method:@*
B. Horn and B. Schunck. Determining Optical Flow. @cite{Artificial Intelligence,}
17:185-203, 1981.
@item For the @code{lk} method:@*
B. D. Lucas T. and Kanade. An Iterative Image Registration Technique with
an Application to Stereo Vision. In @cite{Proceedings of the Seventh International
Joint Conference on Artificial Intelligence,} pages 674-679, Vancouver, BC,
Canada, April 1981.    
@item For the @code{clg} method:@*
A. Bruhn, J. Weickert, and C. Schn@"orr. Lucas/Kanade Meets Horn/Schunck:
Combining Local and Global Optic Flow Methods. @cite{International Journal of
Computer Vision,} 61(3):211-231, 2005.
@item For the @code{bm-sad} method:@*
X. Jiang and M. Lambers. Synthesis of Stereoscopic 3D Videos by Limited Resources of Range Images. 
In @cite{Proceedings of the International Conference on Pattern Recognition
(ICPR) 2006 (accepted for publication).}
@c TODO
@item For the @code{bm-asw} method:@*
K.-J. Yoon and I.-S. Kweon. Locally Adaptive Support-Weight Approach
for Visual Correspondence Search. In @cite{Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition (CVPR),} volume 2, pages 924-931, 
San Diego, CA, USA, June 2005. 
@end itemize

@node Comparing frames
@section Comparing frames

@menu
* diff::
@end menu

@node diff
@subsection diff
@cmindex diff
@code{diff [-s|--statistics] [-o|--output=@var{file}] @var{file-1} @var{file-2}}

@noindent
Shows the differences between the two sources. 

The sources must have the same pixel type, width, and height. This command
produces frames of the same dimensions and of the same pixel type. Each pixel
will be the absolute value of the difference of the corresponding pixels in the
two sources.  For RGB frames, the values will be computed for each channel
separately.

If @option{--statistics} is used, the command will also compute the minimum,
maximum, mean, and median error, and the standard deviation. For RGB frames,
these values will be computed for each channel separately. For YUV frames, only
the Y channel is considered.  The output will be printed to @code{stderr}, unless it
is redirected with the @option{--output} option. If the output is redirected to
@code{stdout} (-), then only the statistics and no frames will be written to @code{stdout}.

@example 
$ cvtool create -w 10 -h 10 -c r255g0b0 > red.pnm
$ cvtool create -w 10 -h 10 -c r0g255b0 > green.pnm
$ cvtool diff -s -o - red.pnm green.pnm
frame pair 1: minimum error      = 255 255 0
frame pair 1: maximum error      = 255 255 0
frame pair 1: median error       = 255 255 0
frame pair 1: mean error         = 255 255 0
frame pair 1: standard deviation = 0 0 0
@end example


@node Stereoscopic image pairs
@section Stereoscopic image pairs

@menu
* dibr::
* stereoview::
* trackdepth::
@end menu

@node dibr
@subsection dibr
@cmindex dibr
@code{dibr -d|--depth=@var{depthsource} -b|--b=@var{b} [-p|--position=@var{p}]
[-z|--zps=@var{z}] [-h|--hole-filling=none|mean|near|far|linear]}

@noindent
Builds stereo images from a source view and corresponding depth maps.

@var{b} is the "eye" distance in pixels. The position of the source view must
be in [-1,+1], where -1 means left view, +1 means right view, and 0 means
intermediate view (this is the default). @var{zps} is the zero parallax
setting. It must be in [0,1]; the default is 0. The hole filling method can be
none, mean color (default), color of nearer/farther neighbor pixel, or
linear color gradient.

@example
$ cvtool dibr -d depth.pgm -b 20 < mono.pnm > stereo.pnm
@end example

@noindent 
See also:
@itemize @asis
@item C. Fehn, K. Hopf, and B. Quante. Key Technologies for an Advanced 3D-TV
System. In @cite{Proceedings of SPIE Three-Dimensional TV, Video and Display
III,} pages 66-80, Philadelphia, PA, USA, October 2004.	
@item L. Zhang and W. J. Tam. Stereoscopic Image Generation Based on Depth
Images for 3D TV. @cite{IEEE Transactions on Broadcasting,} 51(2):191-199, June 2005.	  
@end itemize

@node stereoview
@subsection stereoview
@cmindex stereoview
@code{stereoview anaglyph [-c|--color[=on|off]]
[-g|--glasses=red-cyan|red-green|red-blue]}@*
@code{stereoview 3d-display -f|--format=lr|tb|ci|ri [-w|--width=@var{w}]
[-h|--height=@var{h}]}

@noindent
Prepares stereoscopic image pairs for a display device.

@code{anaglyph}: converts stereo frames (left and right view side by side) into
anaglyph images, viewable with appropriate color 3D glasses. The default is to
create graylevel anaglyphs for @samp{red-blue} glasses. It is advisable to
lighten the images with gamma correction before creating anaglyph images,
because the glasses absorb some lightness.

@code{3d-display}: convert stereo frames (left and right view side by side)
into a format that can be viewed directly on an autostereoscopic 3D display,
for example one by @url{http://www.dti3d.com/,DTI}: just play the resulting
video with any media player in fullscreen mode.  The width and height
parameters should be set to the resolution of the 3D display; the default is
1280x1024. The formats are: @samp{lr} = left-right (S/S on DTI display),
@samp{tb} = top-bottom (T/B on DTI display), @samp{ci} = column-interleaved
(Fr/S on DTI display), @samp{ri} = row-interleaved (F/S on DTI display). If
unsure, try @samp{tb}.

@example
$ cvtool stereoview anaglyph -c -g red-cyan < stereo.pnm > anaglyph.pnm
$ cvtool stereoview 3d-display -f tb < stereo.pnm > dti-stereo.pnm
@end example

@node trackdepth
@subsection trackdepth
@cmindex trackdepth
@code{trackdepth -n|--n=@var{n} -d|--depthmap-list=@var{d0},@var{d1},@dots{}
-f|--flow-forward=@var{flow-fw} -F|--flow-backward=@var{flow-bw}
@var{depthfile0} @var{depthfile1} @dots{}}

@noindent
Creates @var{n} depth maps by using depth tracking with the given flow
information on the given list of depth maps. 

The depth map list contains the numbers of the frames for which a depth map is
available. It must be in ascending order. It is not necessary to give a depth
map for the first and last frame (0 and @var{n}-1), but it may improve the
results. Exactly one depth map file must be given for each entry in the list.

This command uses temporary files that can become quite large.

@example
$ cvtool trackdepth -n 26 -d 0,25 -f flow-fw.dat -F flow-bw.dat \
  depth00.pgm depth25.pgm < video.y4m > depth00-25.pgm
@end example

@noindent 
See also:
@itemize @asis
@item X. Jiang and M. Lambers. DIBR-Based 3D Videos using Non Video Rate Range Image
Stream. In @cite{Proceedings of the IEEE International Conference on Multimedia & Expo 
(ICME) 2006 (accepted for publication).}
@c TODO
@end itemize

@node Miscellaneous
@section Miscellaneous

@menu
* fieldconv::
* mat::
* skeleton::
* sedt::
* vectors::
@end menu

@node fieldconv
@subsection fieldconv
@cmindex fieldconv
@code{fieldconv -i|--input=frame|intfield|floatfield -o|--output=@var{outputtype}
[-l|--low-int=@var{l}] [-h|--high-int=@var{h}] [-L|--low-float=@var{L}] [-H|--high-float=@var{H}]}

@noindent
Converts between fields and frames.
Supported input types are frames, fields with integer values, and fields with
float values.@*
Supported output types are:
@itemize
@item @samp{gray} Graylevel PNM frames.
@item @samp{rgb} Color PNM frames.
@item @samp{int} Fields with 1 integer per element.
@item @samp{int3} Fields with 3 integers per element.
@item @samp{float} Fields with 1 float per element.
@item @samp{float3} Fields with 3 floats per element.
@end itemize
If the input data is fields, then the float or integer values are clamped to
their lower and upper bounds (default is [0,1] for floats and [0,255] for integers)
and then transformed linearly to their destination range ([0,1] for floats and
[0,255] for integers).

This command is mainly useful to visualize the output of commands that produce fields
of integer or floating point values instead of frames. See the examples of @ref{skeleton} 
and @ref{sedt}.

@node mat
@subsection mat
@cmindex mat
@code{mat [-3|--3d]}

@noindent
Computes the Medial Axis Transform (MAT) of the input, with the following properties:
@itemize
@item The MAT is not necessarily thin (1 pixel wide)
@item The MAT is not necessarily connected
@item The original shape can be recovered from the MAT without errors
@end itemize
@xref{skeleton}.

The input must be the SEDT integer fields produced by the @option{sedt} command.
The @option{--3d} option is analogue to the same option of the @option{sedt} command.
@xref{sedt}.

The output will be in form of integer fields that have the same dimensions
as the input. Pixels that do not belong to the MAT will have the value 0.
The value of MAT pixels will be the squared euclidean distance
to the next background pixel.

@example
# Calculate the MAT of an object
$ cvtool sedt < object.pgm | cvtool mat > mat.dat
# Visualize the MAT
$ cvtool fieldconv -i intfield -o gray -l 0 -h 1 < mat.dat > mat.pgm
# Calculate the 3D MAT from volume data
$ voltopgm < object.vol | cvtool sedt --3d | cvtool mat --3d | \
  cvtool fieldconv -i intfield -o gray -l 0 -h 1 | \
  pgmtovol > object.mat.vol
@end example

@noindent 
See also:
@itemize @asis
@item 
E. Remy and E. Thiel. Exact Medial Axis with Euclidean Distance. In @cite{Image and
Vision Computing, 23(2):167-175, 2005.}
@end itemize

@node skeleton
@subsection skeleton
@cmindex skeleton
@code{skeleton [-3|--3d]}

@noindent
Computes the skeletons of the input, with the following properties:
@itemize
@item The skeleton is thin (1 pixel wide)
@item The skeleton is connected
@item The original shape can be recovered from the skeleton with a tolerance 
of 1 pixel
@end itemize
@xref{mat}.

The input will be converted to graylevel if necessary. Black pixels in the
input will be interpreted as background, all others as foreground.

The output will be in form of integer fields that have the same dimensions
as the input. Pixels that do not belong to the skeleton will have the value 0.
The value of skeleton pixels will be the chessboard distance
to the next background pixel.

If @option{--3d} is used, then the input will be interpreted as a 3D cuboid, and
the 3D skeleton will be computed.

Note that the 1-pixel-border of the input is ignored.

@example
# Calculate the skeleton of an object
$ cvtool skeleton < object.pgm > skeleton.dat
# Visualize the skeleton
$ cvtool fieldconv -i intfield -o gray -l 0 -h 1 \
  < skeleton.dat > skeleton.pgm
# Calculate a 3D skeleton from volume data
$ voltopgm < object.vol | cvtool skeleton --3d | \
  cvtool fieldconv -i intfield -o gray -l 0 -h 1 | \
  pgmtovol > object.skel.vol 
@end example

@noindent 
See also:
@itemize @asis
@item 
R. Cardoner and F. Thomas. Residuals + Directional Gaps = Skeletons. In @cite{Pattern
Recognition Letters, 18(4):343-353, 1997}
@item 
F. Romero, L. Ruos, and F. Thomas. Fast Skeletonization of Spatially Encoded
Objects. In @cite{Proceedings of the 15th International Conference on Pattern Recognition 
(ICPR '00), vol. 3, pp. 510-513, 2000.}
@end itemize

@node sedt
@subsection sedt
@cmindex sedt
@code{sedt [-3|--3d]}

@noindent
Computes the Squared Euclidean Distance Transform (SEDT) of the input frames. The result
will be stored in integer fields with the same dimensions as the input. If the
pixel at position (x,y[,z]) in the input is a background pixel (its value is
zero), then its entry in the distance map will be zero.  If the pixel is an
object pixel (its value is not zero), then its entry in the distance map will
be its squared euclidean distance to the next background pixel.

If the option @option{--3d} is used, then the input frames are interpreted as a
3D cuboid, and the 3D SEDT will be computed. In this case, all input frames must
have the same dimensions. Their number determines the depth of the cuboid.  The
result can only be guaranteed to be correct if the width/height/depth of the
input are smaller than 2*sqrt(INT_MAX/2) pixels, or if it is known that the
maximum distance between object pixel and background pixels in the input is
less than sqrt(INT_MAX/2).

@example
# Construct a single white point in a black 3x3 cube
$ cvtool create -w 3 -h 3 > black.ppm
$ cvtool create -w 1 -h 1 -c r255g255b255 > point.ppm
$ cvtool blend -s point.ppm -S -x 1 -y 1 < black.ppm > pointedblack.ppm
$ cvtool merge black.ppm pointedblack.ppm black.ppm > cube.ppm
# Calculate the SEDT of the cube
$ cvtool sedt --3d < cube.ppm > sedt.dat
# Visualize the SEDT
$ cvtool fieldconv -i intfield -o gray < sedt.dat > sedt.pgm
@end example

@noindent 
See also:
@itemize @asis
@item 
C.R. Maurer, R. Qi, and V. Raghavan. A Linear Time Algorithm for Computing
Exact Euclidean Distance Transforms of Binary Images in Arbitrary Dimensions.
In @cite{IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 25(2),
February 2003}.
@end itemize

@node vectors
@subsection vectors
@cmindex vectors
@code{vectors visualize -t|--type=2i|2|3 [-x|--sample-x=@var{x}]
[-y|--sample-y=@var{y}] [-X|--dist-x=@var{dx}] [-Y|--dist-y=@var{dy}]
[-f|--factor=@var{f}]}

@noindent
Reads vector fields in plain text formats, as produced by other commands such
as opticalflow, and visualizes them as a needle diagram. 

The type of the vectors must be known; it can be @samp{2i} for vectors with two
integer components, @samp{2} for vectors with two floating point components,
and @samp{3} for vectors with three floating point components.

Every @var{x}-th vector in horizontal direction and every @var{y}-th vector in
vertical direction will be represented by a needle. The needles will have a
distance of dx pixels in horizontal and dy pixels in vertical direction. The
needle length is the length of the vector after it was scaled with the factor
@var{f}.

Example: @var{x=y=1}, @var{dx=dy=5} will result in a needle diagram that is 5
times wider and higher than the input vector field. Every vector in it is
visualized.  For @var{x=y=5}, the needle diagram is as big as the input vector
field, but only one of 25 vectors is visualized. The default is
@var{x=y=dx=dy=10}, @var{f=1.0}.

@example
$ cvtool vectors visualize -t 2i < flow-fw.dat > flow-fw.pgm
@end example



@node Examples
@chapter Examples

@menu
* Creating a stereoscopic image from a single 2D image::
* Creating a stereoscopic video from a 2D video::
@end menu

@node Creating a stereoscopic image from a single 2D image
@section Creating a stereoscopic image from a single 2D image

@subsection Introduction 

A stereoscopic image is a pair of two images: one right view of a scene and one
left view. When a stereoscopic image is viewed in a way that lets the right eye
see the right view and the left eye the left view, a 3D effect is perceived: 
the human visible system can estimate the distance of an object in the scene from
the slightly different position that each object has in the two views.

Normally, stereoscopic images are created by taking photos from two cameras
that are arranged side by side, like two eyes.  To create a stereoscopic image
from a single 2D image, one has to reverse the distance estimation of the human
visible system: when the distance of an object in the scene is known, its
different positions in the left and right view can be estimated. This process is 
called Depth Image Based Rendering (DIBR).

DIBR uses depth maps are used. A depth map is a graylevel image with the
same dimensions as the original 2D image. For each pixel, it stores the distance
of the corresponding object in the 2D image. Graylevel 0 (black) means "far", and
graylevel 255 (white) means "near".

If you're lucky, you can record depth maps with a range sensor. All others have to
fake the depth maps. Fortunately, it turns out that the human visible system can 
easily be tricked, and that the depth maps do not need to be accurate at all.

@subsection Creating a depth map 

@ref{Figure nasac000} shows an image that was taken from a NASA mission video.
A simplistic depth map for this image was created with the GIMP; it is shown in
figure @ref{Figure nasad000}. It consists of three depth steps ("near", "very near", 
"middle") for parts of the shuttle, and a sphere in the "far" range that 
represents the earth. This sphere may not be visible in the depth map because of 
the dark shades of gray that were used for it. It is probably not necessary anyway.

@float Figure,Figure nasac000
@image{cvtool-example-nasac000,10cm}
@caption{2D image "Nasa"}
@end float

@float Figure,Figure nasad000
@image{cvtool-example-nasad000,10cm}
@caption{Simplistic depth map for 2D image "Nasa"}
@end float

@subsection Depth Image Based Rendering

For Depth Image Based Rendering, it is assumed that the given 2D image comes from a "middle" 
camera. The left and right views of virtual left and right cameras are then computed from this
middle view and the depth map:
@example
$ cvtool dibr -d nasad000.pgm -b 8 \
  < nasac000.ppm > nasac000-stereo.ppm
@end example
The parameter @var{b} specifies the distance between the virtual left and right
cameras, in pixels.

To compute the left and right view, objects have to be moved to left and right.
No information is available about the background that becomes visible when
moving a near object.  This causes disocclusion holes in the left and right
view.  These holes are normally filled with a simple mean color technique.
To make them visible, use the option @code{--hole-filling=none}.

Disocclusion holes always degrade the image quality in comparison to the
original middle view.  To reduce the size of these holes, a moderate smoothing
filter is usually applied to the depth maps before depth image based rendering.
While this further reduces the accuracy of the depth maps, it improves the
viewing experience.
@example
$ cvtool filter gauss -k 3 \
  < nasad000.pgm > nasad000-smoothed.pgm
$ cvtool dibr -d nasad000-smoothed.pgm -b 8 \
  < nasac000.ppm > nasac000-stereo.ppm
@end example

@subsection Viewing the result

The file @code{nasac000-stereo.ppm} now contains the left and right view side by side.
The @code{stereoview} command can be used to prepare this image pair for display on 
different devices. Currently, anaglyph glasses (red-blue, red-green, red-cyan) and 
autostereoscopic monitors from @url{http://www.dti3d.com/,DTI} are supported.

The following command produces a single image that can be viewed with red-cyan anaglyph
glasses:
@example
$ cvtool color -g 1.4 < nasac000-stereo.ppm \
  | cvtool stereoview anaglyph -c --glasses red-cyan \
  > nasac000-stereo-redcyan.ppm
@end example

@node Creating a stereoscopic video from a 2D video
@section Creating a stereoscopic video from a 2D video

The only difference between creating stereoscopic images, as explained in the
previous section @ref{Creating a stereoscopic image from a single 2D image},
and creating stereoscopic videos is that you have many 2D video frames and need
a depth map for each of them.

One way to get these depth maps is a camera with a real-time depth sensor, but most 
people don't have one of these. Depth data is sometimes available for computer generated
videos. For example, it is possible to modify the Quake3 sources to save depth data
when recording demo videos. See @url{http://www.marlam.de/Q3-stereoscopic-videos-based-on-depthmaps-HOWTO.txt}
for instructions on this.

@subsection Depth Tracking

Most of the time, however, the 2D video is all that is available, and manually creating
depth maps for every single frame is not an option.
In these situations, depth tracking is used: starting from few initial depth maps, the
rest is computed by tracking the depth of objects as they move around in the video scene.

The requirements for this are:
@itemize
@item A video scene that does not change too much, so that most objects can be tracked from the
first to the last frame.
@item A motion estimation method
@item A few initial depth maps
@end itemize

As an example, we use the Nasa video scene 
@url{http://spaceflight.nasa.gov/gallery/video/shuttle/sts-114/qtime/114_fdh05_clip3.mov}
from which the example in the previous section was taken.

First, we convert the video to YUV4MPEG2 format. Then, we extract frames 800-1250 with the 
@code{select} command of cvtool. The result is saved to @code{nasa.y4m}.

The motion estimation in both forward and backward direction is done with the commands
@example
$ cvtool opticalflow bm-sad    -k 8 -M 5 -D 0.01 -L 0.5 \
  < nasa.y4m > flow-fw.dat
$ cvtool opticalflow bm-sad -b -k 8 -M 5 -D 0.01 -L 0.5 \
  < nasa.y4m > flow-bw.dat
@end example
Beware: this can take up to several hours to compute!

Initial depth maps are manually created for the first, middle, and last frame, and saved to 
the files @code{nasad000.pgm}, @code{nasad225.pgm}, and @code{nasad450.pgm}.
The result is shown in @ref{Figure nasacd000225450}.

@float Figure,Figure nasacd000225450
@noindent
@image{cvtool-example-nasac000,8cm}@image{cvtool-example-nasad000,8cm}

@noindent
@image{cvtool-example-nasac225,8cm}@image{cvtool-example-nasad225,8cm}

@noindent
@image{cvtool-example-nasac450,8cm}@image{cvtool-example-nasad450,8cm}
@caption{Frames 0, 225, and 450 of the "Nasa" video scene, and the manually created depth maps.}
@end float

Now we have everything that is necessary for depth tracking. The following
command will produce a series of depth maps for frames 0-450 of the video:
@example
$ cvtool trackdepth -n 451 -d 0,225,450 -f flow-fw.dat -F flow-bw.dat \
  nasad000.pgm nasad225.pgm nasad450.pgm > nasad.pgm
@end example
If you view the resulting depth maps as a video, you will notice some errors in the tracking
of objects. Nevertheless, the stereoscopic video created with this sloppy depth data will
be OK!

Now we can use the same commands to produce a stereoscopic video for anaglyph glasses as in the
previous section @ref{Creating a stereoscopic image from a single 2D image}:
@example
$ cvtool filter gauss -k 3 \
  < nasad.pgm > nasad-smoothed.pgm
$ cvtool dibr -d nasad-smoothed.pgm -b 8 \
  < nasa.y4m > nasa-stereo.y4m
$ cvtool color -g 1.4 < nasa-stereo.y4m \
  | cvtool stereoview anaglyph -c --glasses red-cyan \
  > nasa-stereo-redcyan.y4m
@end example

The key to good depth tracking results is good per-pixel motion estimation, and
this is still a very problematic field. You're invited to implement a reliable
and fast motion estimator for cvtool!

The following script summarizes all necessary steps:
@example
@verbatiminclude cvtool-example-nasa-script.sh
@end example

@node Enhancing cvtool
@chapter Enhancing cvtool

Adding new commands to cvtool should be easy. Please look into the subdirectory
@command{cvtool} in the source distribution. Every command is in its own file, and
needs only to be registered in @file{cvtool.c} and @file{Makefile.am}. 

For example, the command @command{foo} must be defined in a file @file{cmd_foo.c}.
It must provide two functions: @code{void cmd_foo_print_help(void)}, which will be called
when the user types @command{cvtool help foo} and should print a short help message,
and @code{int cmd_foo(int argc, char *argv[])} which implements the command and
should behave just like the @code{main} function of a standalone C program.

The following macro adds the function declarations to @file{cvtool.c}: 
@code{COMMAND_DECL(foo)}. The following macros adds the function to the list of known
commands: @code{COMMAND(foo)}. Both macros should be inserted into the existing lists in
ascending alphabetical order.

Finally, automake must know about the new file, so @code{cmd_foo.c} must be added to 
@code{cvtool_SOURCES} in Makefile.am.

Simple existing commands such as @code{cmd_flip.c} or @code{cmd_cut.c} can
serve as examples on how to use @code{cvl_getopt()} to parse the command line,
@code{cvl_io_read()} and @code{cvl_io_write()} to read and write frames, and
other CVL functions to process the frames.

Once the new command works, a test script @file{cmd_foo.sh} should be added to the 
@file{tests} subdirectory (look at the existing scripts for examples), and the 
complete documentation of the command should be added to @file{doc/cvtool.texi}.


@node Command index
@appendix Command index
@menu
* Command index
@end menu

@printindex cm


@bye
